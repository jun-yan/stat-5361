[["index.html", "STAT 5361: Statistical Computing, Fall 2019 Chapter 1 Prerequisites 1.1 A Teaser Example: Likelihood Estimation 1.2 Computer Arithmetics 1.3 Exercises 1.4 Course Project", " STAT 5361: Statistical Computing, Fall 2019 Jun Yan 2020-12-04 Chapter 1 Prerequisites We assume that students can use R/Rstudio comfortably. If you are new to R, an extra amount of hard work should be devoted to make it up. In addition to the official documentations from the R-project, the presentations at a local SIAM workshop in Spring 2018 given by Wenjie Wang, a PhD student in Statistics at the time, can be enlighting: - https://github.com/wenjie2wang/2018-01-19-siam - https://github.com/wenjie2wang/2018-04-06-siam If you have used R, but never paid attention to R programming styles, a style clinic would be a necessary step. A good place to start Hadley Wickham’s tidyverse style guide at http://style.tidyverse.org/. From my experience, the two most commonly overlooked styles for beginners are spacing and indentation. Appropriate spacing and indentation would immediately make crowdly piled code much more eye-friendly. Such styles can be automatically enforced by R packages such as formatr or lintr. Two important styles that cannot be automatically corrected are naming and documentation. As in any programming languate, naming of R objects (variables, functions, files, etc.) shoud be informative, concise, and consistent with certain naming convention. Documentation needs to be sufficient, concise, and kept close to the code; tools like R package roxygen2 can be very helpful. For intermediate R users who want a skill lift, The Advanced R Programming book (Wickham 2019) by Hadley Wickham is available at https://adv-r.hadley.nz/. The source that generated the book is kindly made available at GitHub: https://github.com/hadley/adv-r. It is a great learning experience to complile the book from the source, during which you may pick up many necessary skills. To make R work efficiently, a lot of skills are needed. Even an experienced user would find unified resources of efficient R programming (Gillespie and Lovelace 2016) useful: https://csgillespie.github.io/efficientR/. The homework, exam, and project will be completed by R Markdown. Following the step by step the instructions in Yihui Xie’s online book on bookdown (Xie 2016).at https://bookdown.org/yihui/bookdown/, you will be amazed how quickly you can learn to produce cool-looking documents and even book manuscripts. If you are a keener, you may as well follow Yihui’s blogdown (Xie, Thomas, and Hill 2017), see the online book https://bookdown.org/yihui/blogdown/, to build your own website using R Markdown. All your source code will be version controlled by git and archived on GitHub. RStudio has made using git quite straightforward. The online tutorial by Jenny Bryan, Happy Git and GitHub for the useR at https://happygitwithr.com/, is a very useful tool to get started 1.1 A Teaser Example: Likelihood Estimation In mathematical statistics, we have learned that, under certain regularity conditions, the maximum likelihood estimator (MLE) is consistent, asymptotically normal, and most efficient. The asymptotic variance of the estimator if the inverse of the Fisher information matrix. Specifically, let \\(X_1, \\ldots, X_n\\) be a random sample from a distribution with density \\(f(x; \\theta)\\), where \\(\\theta\\) is a parameter. How do we obtain the MLE? set.seed(123) n &lt;- 100 x &lt;- rgamma(n, shape = 2, scale = 4) hist(x) Package MASS provides a function fitdistr() to obtain the MLE for univariate distributions with a random sample. We can learn two things from this function. First, an objective function representing the negative loglikelihood is formed, depending on the input of the density function, and fed to the optimizer function optim. Second, the variance estimator of the MLE is obtained by inverting the Hessian matrix of the objective function, which is an estimator of the Fisher information matrix. For commonly used distributions, starting values are not necessary. The function computes moment estimator and use them as starting values. MASS::fitdistr(x, densfun = &quot;gamma&quot;) ## Warning in densfun(x, parm[1], parm[2], ...): NaNs produced ## shape rate ## 2.19321713 0.31850407 ## (0.28968120) (0.04724651) For distributions not in the provided list, the densfun needs to be a function returning a density evaluated at its first arguments, in which case, the start argument needs to be a named list to feed to the optimizer. For example, pretend that someone has a fancy distribution which is just a rename of the gamma distribution. Its density function is defined based on the gamma density dgamma(). dfancy &lt;- function(x, shape, scale, log = FALSE) { dgamma(x, shape = shape, scale = scale, log = log) } suppressWarnings(MASS::fitdistr(x, densfun = dfancy, start = list(shape = 10, scale = 20))) ## shape scale ## 2.1931194 3.1400457 ## (0.2897513) (0.4659625) The stats4 package provides MLE using S4 classes. nll &lt;- function(shape, scale) -sum(dfancy(x, shape, scale, TRUE)) suppressWarnings(fit &lt;- stats4::mle(nll, start = list(shape = 10, scale = 10))) stats4::summary(fit) ## Maximum likelihood estimation ## ## Call: ## stats4::mle(minuslogl = nll, start = list(shape = 10, scale = 10)) ## ## Coefficients: ## Estimate Std. Error ## shape 2.193213 0.2896847 ## scale 3.139686 0.4657464 ## ## -2 log L: 557.1586 1.2 Computer Arithmetics Burns (2012) summarizes many traps beginners may fall into. The first one is the floating number trap. Are you surprised by what you see in the following? ## floating point traps .1 == .3 / 3 ## [1] FALSE seq(0, 1, by = .1) == 0.3 ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE seq(0, 1, by = .1) ## [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 unique(c(.3, .4 - .1, .5 - .2, .6 - .3, .7 - .4)) ## [1] 0.3 0.3 0.3 c(.3, .4 - .1, .5 - .2, .6 - .3, .7 - .4) ## [1] 0.3 0.3 0.3 0.3 0.3 options(digits = 20) .1 ## [1] 0.10000000000000000555 .3 / 3 ## [1] 0.099999999999999991673 How does a computer represent a number? Computers use switches, which has only two states, on and off, to represent numbers. That is, it uses the binary number system. With a finite (though large) number switches on a computer, not all real numbers are representable. Binary numbers are made of bits, each of which represent a switch. A byte is 8 bits, which represents one character. 1.2.1 Integers An integer on many computers has length 4-byte or 32-bit. It is represented by the coefficients \\(x_i\\) in \\[ \\sum_{i=1}^{32} x_i 2^{i-1} - 2^{31}, \\] where \\(x_i\\) is either 0 or 1. imax &lt;- .Machine$integer.max imax ## [1] 2147483647 imax + 1L ## Warning in imax + 1L: NAs produced by integer overflow ## [1] NA log(imax, base = 2) ## [1] 30.999999999328192501 u &lt;- 0L b &lt;- 1L for (i in 1L:31L) { u &lt;- u + b b &lt;- b * 2L } ## Warning in b * 2L: NAs produced by integer overflow u ## [1] 2147483647 1000L * 1000L * 1000L ## [1] 1000000000 1000L * 1000L * 1000L * 1000L ## Warning in 1000L * 1000L * 1000L * 1000L: NAs produced by integer overflow ## [1] NA 1000L * 1000L * 1000L * 1000 ## [1] 1e+12 1.2.2 Floating Point A floating point number is represented by \\[ (-1)^{x_0}\\left(1 + \\sum_{i=1}^t x_i 2^{-i}\\right) 2^{k} \\] for \\(x_i \\in \\{0, 1\\}\\), where \\(k\\) is an integer called the exponent, \\(x_0\\) is the sign bit. The fractional part \\(\\sum_{i=1}^t x_i 2^{-i}\\) is the significand. By convention (for unique representation), the exponent is chosen so that the fist digit of the significand is 1, unless it would result in the exponent being out of range. A standard double precision representation uses 8 bytes or 64 bits: a sign bit, an 11 bit exponent, and \\(t = 52\\) bits for the significand. With 11 bits there are \\(2^{11} = 2048\\) possible values for the exponent, which are usually shifted so that the allowed values range from \\(-1022\\) to 1023, again with one special sign value. The IEEE standard for floating point arithmetic calls for basic arithmetic operations to be performed to higher precision, and then rounded to the nearest representable floating point number. Arithmetic underflow occurs where the result of a calculation is a smaller number than what the computer can actually represent. Arithmetic overflow occurs when a calculation produces a result that is greater in magnitude than what the computer can represent. Here is a demonstration (Gray 2001). options(digits = 20) .Machine$double.eps ## [1] 2.2204460492503130808e-16 .Machine$double.base ^ .Machine$double.ulp.digits ## [1] 2.2204460492503130808e-16 1 + .Machine$double.eps == 1 ## [1] FALSE 1 + .Machine$double.base ^ (.Machine$double.ulp.digits - 1L) == 1 ## [1] TRUE ## largest possible significand u &lt;- 0 for (i in 1L:53) u &lt;- u + 2^(-i) u ## [1] 0.99999999999999988898 ## and the largest possible exponent--note that calculating 2^1024 ## directly overflows u * 2 * 2 ^ 1023 ## [1] 1.7976931348623157081e+308 ## next largest floating point number overflows (u * 2 * 2 ^ 1023) * (1 + 1/2^52) ## [1] Inf ## smallest possible mantissa and smallest possible exponent 1 / 2^52 * 2^(-1022) ## [1] 4.9406564584124654418e-324 1 / 2^52 * 2^(-1022) / 2 ## [1] 0 1.2.3 Error Analysis More generally, a floating point number with base \\(\\beta\\) can be represented as \\[ (-1)^{x_0}\\left(\\sum_{i=1}^t x_i \\beta^{-i}\\right) \\beta^{k}, \\] where \\(x_0 \\in \\{0, 1\\}\\), \\(x_i \\in \\{0, 1, \\ldots, \\beta - 1\\}\\), \\(i = 1, \\ldots, t\\), and \\(E_{\\min} \\le k \\le E_{\\max}\\) for some \\(E_{\\min}\\) and \\(E_{\\max}\\). For a binary system \\(\\beta = 2\\) while for the decimal system \\(\\beta = 10\\). To avoid multiple representations, a normalized representation is defined by forcing the first significant digit (\\(x_1\\)) to be non-zero. The numbers \\(\\{x: |x| &lt; \\beta^{E_{\\min} - 1}\\}\\) (called subnormals) can not be normalized and, are sometimes excluded from the system. If an operation results in a subnormal number underflow is said to have occurred. Similarly if an operation results in a number with the exponent \\(k &gt; E_{\\max}\\), overflow is said to have occurred. Let \\(f(x)\\) be the floating point representation of \\(x\\). The relative error of \\(f(x)\\) is \\(\\delta_x = [f(x) - x] / x\\). The basic formula for error analysis is \\[ f(x \\circ y) = (1+ \\epsilon_m) (x \\circ y) \\] if \\(f(x \\circ y)\\) does not overflow or underflow, where \\(\\circ\\) is an operator (e.g., add, subtract, multiple, divide, etc.), \\((x \\circ y)\\) is the exact result, and \\(\\epsilon_m\\) is the smallest positive floating-point number \\(z\\) such that \\(1 + z \\ne 1\\). Add demonstration from Section 1.3 of Gray (2001); see also [notes] (https://people.eecs.berkeley.edu/~demmel/cs267/lecture21/lecture21.html). (Section 1.4 from Gray) Consider computing \\(x + y\\), where \\(x\\) and \\(y\\) have the same sign. Let \\(\\delta_x\\) and \\(\\delta_y\\) be the relative error in the floating point representation of \\(x\\) and \\(y\\), respectively (e.g., \\(\\delta_x = [f(x) - x]/x\\), so \\(f(x) = x(1 + \\delta_x)\\)). What the computer actually calculates is the sum of the floating point representations \\(f (x) + f (y)\\), which may not have an exact floating point representation, in which case it is rounded to the nearest representable number \\(f(f(x) + f(y))\\). Let \\(\\delta_s\\) be the relative error of the \\(f(f(x) + f(y))\\). Then, \\[\\begin{align*} \\phantom{ = } &amp; |f(f(x) + f(y)) - (x+y)| \\\\ = &amp; |f(f(x) + f(y)) - f(x) - f(y) + f(x) - x + f(y) - y| \\\\ \\le &amp; |\\delta_s[f(x) + f(y)]| + |\\delta_x x| + |\\delta_y y|\\\\ \\le &amp; |x+y|(\\epsilon_m + \\epsilon^2_m) + |x+y| \\epsilon_m \\\\ \\approx &amp; 2\\epsilon_m |x+y|, \\end{align*}\\] where the higher order terms in \\(\\epsilon_m\\) have been dropped, since they are usually negligible. Thus \\(2\\epsilon_m\\) is an (approximate) bound on the relative error in a single addition of two numbers with the same sign. Example 1.1 (Computing sample sum) (Section 1.5.1 of Srivistava (2009)) Let \\(x_1, \\ldots, x_n\\) be the observations from a random of size \\(n\\). The simplest algorithm to compute the sample sum is to start from \\(s_0 = 0\\) and add one term each time \\(s_j = s_{j-1} + x_j\\). Each addition may result in a number that is not a floating number, with an error denoted by multiple \\((1 + \\epsilon)\\) to that number. For example, when \\(n = 3\\), suppose that \\((x_1, x_2, x_3)\\) are floating numbers. We have: \\[\\begin{align*} f(s_1) &amp;= (0 + x_1)(1 + \\epsilon_1)\\\\ f(s_2) &amp;= (f(s_1) + x_2)(1 + \\epsilon_2)\\\\ f(s_3) &amp;= (f(s_2) + x_3)(1 + \\epsilon_3) \\end{align*}\\] It can be seen that \\[\\begin{align*} f(s_3) = (x_1 + x_2 + x_3) + x_1 (\\epsilon_1 + \\epsilon_2 + \\epsilon_3) + x_2 (\\epsilon_2 + \\epsilon_3) + x_3(\\epsilon_3) + o(\\epsilon_m). \\end{align*}\\] The cumulative error is approximately \\[\\begin{align*} &amp;\\phantom{ = } \\| f(s_3) - (x_1 + x_2 + x_3)\\| \\\\ &amp;\\sim \\| x_1 (\\epsilon_1 + \\epsilon_2 + \\epsilon_3) + x_2 (\\epsilon_2 + \\epsilon_3) + x_3(\\epsilon_3) \\|\\\\ &amp;\\le \\|x_1\\| (\\|\\epsilon_1\\| + \\|\\epsilon_2\\| + \\|\\epsilon_3\\|) + \\|x_2\\| (\\|\\epsilon_2\\| + \\|\\epsilon_3\\|) + \\|x_3\\| \\|\\epsilon_3\\| \\\\ &amp;\\le (3 \\|x_1\\| + 2\\|x_2\\| + \\|x_3\\|) \\epsilon_m. \\end{align*}\\] This suggests that better accuracy can be achieved at the expense of sorting in increasing order before computing the sum. Todo: design a decimal system with limited precision to demonstrate the error analysis Subtracting one number from another number of similar magnitude can lead to large relative error. This is more easily illustrated using a decimal system (\\(\\beta = 10\\)); see Section~1.4 of Srivastava (2009). For simplicity, consider the case with \\(t = 4\\). Let \\(x = 122.9572\\) and \\(y = 123.1498\\). Their floating point representations are (1230, 3) and (1231, 3). The resulting difference is \\(-0.1\\) while the actual answer is \\(-0.1926\\). The idea is the same on a binary system. Consider an extreme case: \\[\\begin{align*} f(x) &amp;= 1 / 2 + \\sum_{i=2}^{t-1} x_i / 2^i + 1 / 2^t,\\\\ f(y) &amp;= 1 / 2 + \\sum_{i=2}^{t-1} x_i / 2^i + 0 / 2^t. \\end{align*}\\] The absolute errors of \\(f(x)\\) and \\(f(y)\\) are in \\((0, 1/2^{t+1})\\). The true difference \\(x - y\\) could be anywhere in \\((0, 1 / 2^{t-1})\\) The computed subtraction is \\(f(x) - f(y) = 1 / 2^t\\). So the relative error can be arbitrarily large. The error from subtraction operation also explains why approximating \\(e^{x}\\) by partial sums does not work well for negative \\(x\\) with a large magnitude. Consider an implementation of the exponential function with the Taylor series \\(\\exp(x) = \\sum_{i=0}^{\\infty} x^i / i!\\). fexp &lt;- function(x) { i &lt;- 0 expx &lt;- 1 u &lt;- 1 while (abs(u) &gt; 1.e-8 * abs(expx)) { i &lt;- i + 1 u &lt;- u * x / i expx &lt;- expx + u } expx } options(digits = 10) x &lt;- c(10, 20, 30) cbind(exp( x), sapply( x, fexp)) ## [,1] [,2] ## [1,] 2.202646579e+04 2.202646575e+04 ## [2,] 4.851651954e+08 4.851651931e+08 ## [3,] 1.068647458e+13 1.068647454e+13 cbind(exp(-x), sapply(-x, fexp)) ## [,1] [,2] ## [1,] 4.539992976e-05 4.539992956e-05 ## [2,] 2.061153622e-09 5.621884467e-09 ## [3,] 9.357622969e-14 -3.066812359e-05 The accuracy is poor for \\(x &lt; 0\\). The problem in accuracy occurs because the terms alternate in sign, and some of the terms are much greater than the final answer. It can be fixed by noting that \\(\\exp(-x) = 1 / \\exp(x)\\). fexp2 &lt;- function(x) { if (x &gt;= 0) fexp(x) else 1 / fexp(-x) } cbind(exp(-x), sapply(-x, fexp2)) ## [,1] [,2] ## [1,] 4.539992976e-05 4.539992986e-05 ## [2,] 2.061153622e-09 2.061153632e-09 ## [3,] 9.357622969e-14 9.357623008e-14 1.2.4 Condition Number (Wiki) In numerical analysis, the condition number of a function with respect to an argument measures how much the output value of the function can change for a small change in the input argument. This is used to measure how sensitive a function is to changes or errors in the input, and how much error in the output results from an error in the input. The condition number is an application of the derivative, and is formally defined as the value of the asymptotic worst-case relative change in output for a relative change in input. The “function” is the solution of a problem and the “arguments” are the data in the problem. In particular, \\(C(x)\\) is called the condition number of a function \\(f\\) at a given point \\(x\\) if it satisfies the condition \\[ |\\mbox{relative change in } f(x)| \\sim C(x)|\\mbox{relative change in } x| . \\] The condition number is frequently applied to questions in linear algebra, in which case the derivative is straightforward but the error could be in many different directions, and is thus computed from the geometry of the matrix. More generally, condition numbers can be defined for non-linear functions in several variables. A problem with a low condition number is said to be well-conditioned, while a problem with a high condition number is said to be ill-conditioned. The condition number is a property of the problem. Paired with the problem are any number of algorithms that can be used to solve the problem, that is, to calculate the solution. Some algorithms have a property called backward stability. In general, a backward stable algorithm can be expected to accurately solve well-conditioned problems. Numerical analysis textbooks give formulas for the condition numbers of problems and identify the backward stable algorithms. In the exponential function example, the first implementation is unstable for large negative \\(x\\) while the second is stable. It is important in likelihood maximization to work on the log scale. Use argument log in dpq functions instead of taking logs. This can be important in probalistic networks and MC(MC) where \\(P = P_1 · P_2 \\cdots · P_n\\) quickly underflows to zero. It is also important to use log1p and expm1 alike when caculating \\(\\log(1 + x)\\) and \\(\\exp(x)- 1\\) when \\(|x| \\ll 1\\). One example is the evaluation of distribution and density function of the generalized extreme value (GEV) distribution. The GEV distribution has distribution function \\[\\begin{equation*} F(x; \\mu, \\sigma, \\xi) = \\begin{cases} \\exp[- \\left[ 1 + \\left(\\frac{x - \\mu}{\\sigma}\\right) \\xi\\right]^{-1 / \\xi} &amp; \\xi \\ne 0, \\quad (1 + \\xi (x - \\mu) / \\sigma) &gt; 0,\\\\ \\exp[e^{ -(x - \\mu) / \\sigma}] &amp; \\xi = 0, \\end{cases} \\end{equation*}\\] for \\(\\mu \\in R\\), \\(\\sigma &gt; 0\\), \\(\\xi \\in R\\). curve(evir::pgev(1, xi = x), -1e-13, 1e-13, n = 1025) curve(texmex::pgev(1, 0, 1, x), -1e-13, 1e-13, n = 1025) Figure 1.1: Two implementations of GEV distribution function when \\(\\xi\\) is close to zero. Figure 1.1 shows a comparison of evaluating the GEV distribution function at \\(x = 1\\) for \\(\\mu = 0\\), \\(\\sigma = 1\\), and a sequence of \\(\\xi\\) values near zero using two implementations. 1.3 Exercises Use git to clone the source of Hadley Wickham’s Advanced R Programming from his GitHub repository to a local space on your own computer. Build the book using RStudio. During the building process, you may see error messages due to missing tools on your computer. Read the error messages carefully and fix them, until you get the book built. You may need to install some R packages, some fonts, some latex packages, and some building tools for R packages. On Windows, some codes for parallel computing may not work and need to be swapped out. Document your computing environment (operating system, R/RStudio, Shell, etc.) and the problems you encountered, as well as how you solved them in an R Markdown file named README.Rmd. Push it to your homework GitHub repository so that it can help other students to build the book. Use bookdown or rmarkdown to produce a report for the following task. Consider approximation of the distribution function of \\(N(0, 1)\\), \\[\\begin{equation} \\Phi(t) = \\int_{-\\infty}^t \\frac{1}{\\sqrt{2\\pi}} e^{-y^2 / 2} \\mathrm{d}y, \\tag{1.1} \\end{equation}\\] by the Monte Carlo methods: \\[\\begin{equation} \\hat\\Phi(t) = \\frac{1}{n} \\sum_{i=1}^n I(X_i \\le t), \\end{equation}\\] where \\(X_i\\)’s are a random sample from \\(N(0, 1)\\), and \\(I(\\cdot)\\) is the indicator function. Experiment with the approximation at \\(n \\in \\{10^2, 10^3, 10^4\\}\\) at \\(t \\in \\{0.0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72\\}\\) to form a table. The table should include the true value for comparison. Further, repeat the experiment 100 times. Draw box plots of the 100 approximation errors at each \\(t\\) using ggplot2 (Wickham et al. 2020) for each \\(n\\). The report should look like a manuscript, with a title, an abstract, and multiple sections. It should contain at least one math equation, one table, one figure, and one chunk of R code. The template of our Data Science Lab can be helpful: https://statds.org/template/, the source of which is at https://github.com/statds/dslab-templates. Explain how .Machine$double.xmax, .Machine$double.xmin, .Machine$double.eps, and .Machine@double.neg.eps are defined using the 64-bit double precision floating point arithmetic. Give the 64-bit representation for these machine constants as well as the double precision number 1.0, 0.0, and \\(\\pi\\). Find the first 10-digit prime number occurring in consecutive digits of \\(e\\) http://mathworld.wolfram.com/news/2004-10-13/google/. Hint: How can \\(e\\) be represented to an arbitrary precision? 1.4 Course Project Each student is required to work independently on a class project on a topic of your choice that involves computing. Examples are an investigation of the properties of a methodology you find interesting, a comparison of several methods on a variety of problems, a comprehensive analysis of a real data with methodologies from the course, or an R package. The project should represent new work, not something you have done for another course or as part of your thesis. I have a collection of small problems that might be suitable. Projects from Kaggle data science competitions may be good choices too. Project proposal is due in week 7, the middle of the semester. This is a detailed, one-page description of what you plan to do, including question(s) to be addressed and models/methods to be used. Project interim report is due in week 12. This informal report will indicate that your project is ``on track’’. The report includes results obtained thus far and a brief summary of what they mean and what remains to be done. Students often start working on this too late. Your do not want to make the same mistake. Final project report is due in the exam week. The final form of the report should use the Data Science Lab template, of no more than 6 pages (single spaced, font no smaller than 11pt, 1 inch margin, with references, graphics and tables included). With more effort, a good project can turn into a paper and be submitted to ENAR student paper competition (Oct. 15) and ASA student paper competition (Dec. 15). Project ideas: An animated demonstration of different methods in optimx with data examples. Accelerated EM algorithm Simulation from empirical distributions joined by copulas References "],["nla.html", "Chapter 2 Numerical Linear Algebra", " Chapter 2 Numerical Linear Algebra This chapter should cover basics of vector/matrix operation; matrix factorization, and their applications in statisticcs. "],["optim.html", "Chapter 3 Optimization 3.1 Univariate Optimizations 3.2 Multivariate Optimization 3.3 MM Algorithm 3.4 An Example: LASSO with Coordinate Descent 3.5 Exercises", " Chapter 3 Optimization Recall the MLE example in Chapter 1. Consider a random sample \\(X_1, \\ldots, X_n\\) of size \\(n\\) coming from a univariate distribution with density function \\(f(x | \\theta)\\), where \\(\\theta\\) is a parameter vector. The MLE \\(\\hat\\theta_n\\) of the unknown parameter \\(\\theta\\) is obtained by maximizing the loglikelihood function \\[ l(\\theta) = \\sum_{i=1}^n \\log f(X_i | \\theta) \\] with respect to \\(\\theta\\). Typically, \\(\\hat\\theta\\) is obtained by solving the score equation \\[ l&#39;(\\theta) = \\sum_{i=1}^n \\frac{\\partial}{\\partial \\theta} \\log f(X_i; \\theta) = 0, \\] i.e., the derivative of the loglikelihood function equated to zero. From mathematical statistics, it is known that, under certain regularity conditions, \\[\\begin{align*} \\mathbb{E}\\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta) &amp;= 0,\\\\ \\mathbb{E}\\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta) \\left[\\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta) \\right]^{\\top} &amp;= - \\mathbb{E} \\frac{\\partial^2}{\\partial \\theta \\partial \\theta^{\\top}} \\log f(X; \\theta). \\end{align*}\\] The expectation in the second equation is known as the Fisher information \\(I(\\theta)\\), a nonnegative definite matrix. Large sample results state that, as \\(n \\to \\infty\\), \\(\\hat\\theta_n\\) is consistent for \\(\\theta\\) and \\(\\sqrt{n} (\\hat\\theta_n - \\theta)\\) converges in distribution to \\(N(0, I^{-1}(\\theta))\\). The asymptotic variance of \\(\\hat\\theta\\) can be estimated by inverting the observed Fisher information matrix \\(l&#39;&#39;(\\hat\\theta_n)\\). More generally in Statistics, M-estimators are a broad class of extremum estimators obtained by maximizing an data dependent objective function. Both non-linear least squares and maximum likelihood estimation are special cases of M-estimators. The definition of M-estimators was motivated by robust statistics, which contributed new types of M-estimators. When the objective function is smooth, the M-estimator can be obtained by solving the corresponding “score” equation. Clearly, optimization or root-finding are very important in Statistics. 3.1 Univariate Optimizations Optimization and root finding are closely related. Consider maximization of a smooth and differentiable function \\(g(x)\\). A necessary condition at the maximum is \\(f(x) = g&#39;(x) = 0\\). Univariate illustrations help to gain insights about the ideas. 3.1.1 Bisection Method The bisection method repeatedly bisects an interval and then selects a subinterval in which a root must lie for further processing. It is a very simple and robust method, but relatively slow. The method is applicable for solving the equation \\(f(x) = 0\\) for the real variable \\(x\\), where \\(f\\) is a continuous function defined on an interval \\([a, b]\\) and \\(f(a)\\) and \\(f(b)\\) have opposite signs. This method is illustrated with an animation using the package animation (Xie 2018). animation::bisection.method() 3.1.2 Newton’s Method A fast approach to find roots of a differentiable function \\(f(x)\\). The methods starts from some initial value \\(x_0\\), and for \\(t = 0, 1, \\ldots\\), compute \\[\\begin{align*} x_{t+1} = x_t - \\frac{f(x_t)}{f&#39;(x_t)} \\end{align*}\\] until \\(x_t\\) converges. The method is based on a linear expansion of \\(f(x)\\). The method is also known as Newton–Raphson iteration. It needs an initial value \\(x_0\\). If \\(f(x) = 0\\) has multiple solutions, the end result depends on \\(x_0\\). Applied to optimization of \\(g\\), this method requires the Hessian \\(g&#39;&#39;\\), which can be difficult to obtain, especially for multivariate functions. Many variants of Newton’s method avoid the computation of the Hessian. For example, to obtain MLE with likelihood \\(l(\\theta)\\), Fisher scoring replaces \\(-l&#39;&#39;(\\theta_t)\\) with \\(I(\\theta_t)\\). Generally, one uses Fisher scoring in the beginning to make rapid improvements, and Newton’s method for refinement near the end. The secant method approximates \\(f&#39;(x_t)\\) by \\[\\begin{align*} \\frac{f(x_t) - f(x_{t-1})}{x_t - x_{t-1}}. \\end{align*}\\] Given initial values \\(x_0\\) and \\(x_1\\), the iteration is \\[\\begin{align*} x_{t+1} = x_t - \\frac{f(x_t)(x_t- x_{t-1})}{f(x_t) - f(x_{t-1})}. \\end{align*}\\] 3.1.3 Fixed Point Iteration A fixed point of a function is a point whose evaluation by that function equals to itself, i.e., \\(x = G(x)\\). Fixed point iteration: the natural way of hunting for a fixed point is to use \\(x_{t+1} = G(x_t)\\). Definition 3.1 A function \\(G\\) is contractive on \\([a,b]\\) if \\[\\begin{align*} (1).\\,\\, &amp; G(x)\\in [a,b] \\mbox{ whenever } x\\in [a,b],\\\\ (2).\\,\\, &amp; |G(x_1) - G(x_2)| \\leq \\lambda |x_1-x_2| \\mbox{ for all } x_1,x_2\\in [a,b] \\mbox{ and some } \\lambda\\in [0,1). \\end{align*}\\] Theorem 3.1 If \\(G\\) is contractive on \\([a,b]\\), then there is a unique fixed point \\(x^*\\in [a,b]\\), and the fixed point iteration convergence to it when starting inside the interval. Convergence: \\(|x_{t+1}-x_{t}|=|G(x_t)-G(x_{t-1})|\\leq \\lambda |x_t - x_{t-1}|\\leq \\lambda^{t}|x_1-x_0| \\rightarrow 0\\), as \\(t\\rightarrow \\infty\\). It follows that \\(\\{x_t\\}\\) convergent to a limit \\(x^*\\). Application in root finding: for solving \\(f(x)=0\\), we can simply let \\(G(x) = x + \\alpha f(x)\\), where \\(\\alpha \\neq 0\\) is a constant. Required Lipschitz condition: \\(|x - y + \\alpha [f(x) - f(y)]| \\le \\lambda|x-y|\\), for some \\(\\lambda \\in [0,1)\\) and for all \\(x,y\\in [a,b]\\). This holds if \\(|G&#39;(x)|\\leq \\lambda\\) for some \\(\\lambda \\in [0,1)\\) and for all \\(x\\in [a,b]\\), i.e., \\(|1+\\alpha f&#39;(x)|\\leq\\lambda\\). (use mean value theorem.) Newton’s methods: \\(G(x) = x - f(x)/f&#39;(x)\\). So it is as if \\(\\alpha_t\\) is chosen adaptively as \\(\\alpha_t=-1/f&#39;(x_t)\\). This leads to a faster convergence order (quadratic). 3.2 Multivariate Optimization Consider maximizing a real-valued objective function \\(g(x)\\) of \\(p\\)-dimensional vector \\(x\\). 3.2.1 Newton-Raphson Method The Newton-Raphson method is a generalization of univariate Newton’s root finding algorithm to the multivariate case. 3.2.2 Variants of Newton-Raphson Method The motivation is to avoid the calculation of the Hessian matrix in updatings with the form \\[ x^{(t + 1)} = x^{(t)} - (M^{(t)})^{-1} g&#39;(x), \\] where \\(g&#39;\\) is the gradient of \\(g\\) and \\(M\\) is a substitute of \\(g&#39;&#39;(x)\\). 3.2.2.1 Fisher Scoring Choose \\(M\\) as the negative Fisher information matrix. For location-families, it can be shown that the information matrix is free of the location parameter. 3.2.2.2 Steepest Ascent Choose \\(M = \\alpha^{(t)} I_p\\) for \\(\\alpha^{(t)} &gt; 0\\) so the updating in the direction of he steepest ascent. 3.2.2.3 Discrete Newton Approximate the Hessian matrix with finite-difference quotients. 3.2.2.4 Fixed-Point Iteration Choose \\(M^{(t)} = M\\) for all \\(t\\). An example is \\(M = g&#39;&#39;(x_0)\\). 3.2.2.5 Quasi-Newton Quasi-Newton methods avoids Hessian matrix by constructing approximations of the inverse Hessian. The inverse Hessian is built up from gradient information obtained at various points. Rank-two update. The celebrated BFGS is a rank-two update method. Box constraints can be allowed with L-BFGS-B. 3.2.2.6 Coordinate Descent Coordinate descent algorithms optimize a objective function with respect to a single parameter or a block of parameters at a time, iteratively cycling through all parameters until convergence is reached. How to determine the blocks of parameters is problem-specific. The method is ideal for problems that have a simple closed form solution in a single/lower dimension but lack one in higher dimensions. % The method is also called backfitting or Gauss–Seidel iteration. It is very commonly used in fitting penalized regression. The concept also appears in many well-known estimation problems. The simple technique can be surprisingly efficient and scalable. Consider objective function \\[ f(\\beta) = g(\\beta) + \\sum_{j=1}^{p}h_j(\\beta_j), \\] where \\(g\\) is convex and differentiable and each \\(h_i\\) is convex. The second part is usually non-smooth, but is separable. Coordinate descent start with some initial guess \\(\\beta^{(0)}\\), repeat the following for \\(k=1,2,3...\\): \\[\\begin{align*} \\beta_1^{(k)} &amp; = \\arg\\min_{\\beta_1}f(\\beta_1,\\beta_2^{(k-1)},\\ldots,\\beta_p^{(k-1)}),\\\\ \\beta_2^{(k)} &amp; = \\arg\\min_{\\beta_2}f(\\beta_1^{(k)},\\beta_2, \\beta_3^{(k-1)},\\ldots,\\beta_p^{(k-1)}),\\\\ &amp; \\ldots\\\\ \\beta_p^{(k)} &amp; = \\arg\\min_{\\beta_p}f(\\beta_1^{(k)},\\ldots,\\beta_{p-1}^{(k)},\\beta_p). \\end{align*}\\] It can be shown that if we are at a point \\(\\beta\\) such that \\(f(\\beta)\\) is minimized along each coordinate axis, we have found a global minimizer. Remarks: Order of cycle through coordinates is arbitrary. Can replace individual coordinates with blocks of coordinates. Same idea has been applied to many non-convex problems. As long as the objective function is monotone decreasing, the convergence is guaranteed. 3.2.2.7 Conjugate Gradient 3.2.2.8 Gauss-Newton Non-linear least squares. 3.2.3 Nelder-Mead (Simplex) Algorithm Not even the gradient is needed. Possible moves are: reflection; expansion; outer contraction; inner contraction; shrinkage. Consider minimizing this simple function. f1 &lt;- function(x) { x1 &lt;- x[1] x2 &lt;- x[2] x1^2 + 3*x2^2 } Apparently the minimizer is \\((0, 0)\\). Let’s track all the points at which the function is evaluated in the Nelder-Mead algorithm. trace(f1, exit = quote(print(c(returnValue(), x)))) ## [1] &quot;f1&quot; optim(c(1, 1), f1, control = list(trace = TRUE)) ## Nelder-Mead direct search function minimizer ## Tracing fn(par, ...) on exit ## [1] 4 1 1 ## function value for initial parameters = 4.000000 ## Scaled convergence tolerance is 5.96046e-08 ## Stepsize computed as 0.100000 ## Tracing fn(par, ...) on exit ## [1] 4.21 1.10 1.00 ## Tracing fn(par, ...) on exit ## [1] 4.63 1.00 1.10 ## BUILD 3 4.630000 4.000000 ## Tracing fn(par, ...) on exit ## [1] 3.64 1.10 0.90 ## Tracing fn(par, ...) on exit ## [1] 3.2425 1.1500 0.8000 ## EXTENSION 5 4.210000 3.242500 ## Tracing fn(par, ...) on exit ## [1] 3.0225 1.0500 0.8000 ## Tracing fn(par, ...) on exit ## [1] 2.520625 1.025000 0.700000 ## EXTENSION 7 4.000000 2.520625 ## Tracing fn(par, ...) on exit ## [1] 2.130625 1.175000 0.500000 ## Tracing fn(par, ...) on exit ## [1] 1.781406 1.262500 0.250000 ## EXTENSION 9 3.242500 1.781406 ## Tracing fn(par, ...) on exit ## [1] 1.361406 1.137500 0.150000 ## Tracing fn(par, ...) on exit ## [1] 1.371602 1.131250 -0.175000 ## REFLECTION 11 2.520625 1.361406 ## Tracing fn(par, ...) on exit ## [1] 2.160625 1.375000 -0.300000 ## Tracing fn(par, ...) on exit ## [1] 1.665156 1.287500 -0.050000 ## LO-REDUCTION 13 1.781406 1.361406 ## Tracing fn(par, ...) on exit ## [1] 1.418906 1.162500 -0.150000 ## Tracing fn(par, ...) on exit ## [1] 1.417656 1.187500 -0.050000 ## LO-REDUCTION 15 1.665156 1.361406 ## Tracing fn(par, ...) on exit ## [1] 1.143906 1.037500 0.150000 ## Tracing fn(par, ...) on exit ## [1] 1.020156 0.912500 0.250000 ## EXTENSION 17 1.417656 1.020156 ## Tracing fn(par, ...) on exit ## [1] 1.351406 0.862500 0.450000 ## Tracing fn(par, ...) on exit ## [1] 1.207539 0.943750 0.325000 ## LO-REDUCTION 19 1.361406 1.020156 ## Tracing fn(par, ...) on exit ## [1] 1.058477 0.718750 0.425000 ## Tracing fn(par, ...) on exit ## [1] 1.0587915 0.8234375 0.3562500 ## LO-REDUCTION 21 1.207539 1.020156 ## Tracing fn(par, ...) on exit ## [1] 0.8401563 0.6875000 0.3500000 ## Tracing fn(par, ...) on exit ## [1] 0.7071191 0.5593750 0.3625000 ## EXTENSION 23 1.058477 0.707119 ## Tracing fn(par, ...) on exit ## [1] 0.672666 0.753125 0.187500 ## Tracing fn(par, ...) on exit ## [1] 0.6075610 0.7703125 0.0687500 ## EXTENSION 25 1.020156 0.607561 ## Tracing fn(par, ...) on exit ## [1] 0.2726001 0.4171875 0.1812500 ## Tracing fn(par, ...) on exit ## [1] 0.09345764 0.16953125 0.14687500 ## EXTENSION 27 0.707119 0.093458 ## Tracing fn(par, ...) on exit ## [1] 0.2094733 0.3804688 -0.1468750 ## Tracing fn(par, ...) on exit ## [1] 0.18193546 0.42519531 -0.01953125 ## LO-REDUCTION 29 0.607561 0.093458 ## Tracing fn(par, ...) on exit ## [1] 0.04113010 -0.17558594 0.05859375 ## Tracing fn(par, ...) on exit ## [1] 0.42918962 -0.64853516 0.05351562 ## REFLECTION 31 0.181935 0.041130 ## Tracing fn(par, ...) on exit ## [1] 0.3378516 -0.4312500 0.2250000 ## Tracing fn(par, ...) on exit ## [1] 0.04974852 0.21108398 0.04160156 ## HI-REDUCTION 33 0.093458 0.041130 ## Tracing fn(par, ...) on exit ## [1] 0.02450188 -0.13403320 -0.04667969 ## Tracing fn(par, ...) on exit ## [1] 0.1434302 -0.2858154 -0.1434570 ## REFLECTION 35 0.049749 0.024502 ## Tracing fn(par, ...) on exit ## [1] 0.2737758 -0.5207031 -0.0296875 ## Tracing fn(par, ...) on exit ## [1] 0.002488067 0.028137207 0.023779297 ## HI-REDUCTION 37 0.041130 0.002488 ## Tracing fn(par, ...) on exit ## [1] 0.02478057 0.06968994 -0.08149414 ## Tracing fn(par, ...) on exit ## [1] 0.006549060 0.008370972 -0.046472168 ## LO-REDUCTION 39 0.024502 0.002488 ## Tracing fn(par, ...) on exit ## [1] 0.03081047 0.17054138 0.02398682 ## Tracing fn(par, ...) on exit ## [1] 0.005876474 -0.057889557 -0.029013062 ## HI-REDUCTION 41 0.006549 0.002488 ## Tracing fn(par, ...) on exit ## [1] 0.006555205 -0.038123322 0.041238403 ## Tracing fn(par, ...) on exit ## [1] 0.001817881 -0.003252602 -0.024544525 ## HI-REDUCTION 43 0.005876 0.001818 ## Tracing fn(par, ...) on exit ## [1] 0.009245382 0.082774162 0.028247833 ## Tracing fn(par, ...) on exit ## [1] 0.001164443 -0.022723627 -0.014697838 ## HI-REDUCTION 45 0.002488 0.001164 ## Tracing fn(par, ...) on exit ## [1] 0.01484345 -0.05411344 -0.06302166 ## Tracing fn(par, ...) on exit ## [1] 7.034119e-05 7.574546e-03 2.079058e-03 ## HI-REDUCTION 47 0.001818 0.000070 ## Tracing fn(par, ...) on exit ## [1] 0.0005681964 -0.0118964791 0.0119257450 ## Tracing fn(par, ...) on exit ## [1] 0.0001184377 -0.0097355098 0.0028081775 ## LO-REDUCTION 49 0.001164 0.000070 ## Tracing fn(par, ...) on exit ## [1] 0.001573548 0.020562664 0.019585073 ## Tracing fn(par, ...) on exit ## [1] 0.0002542833 -0.0119020544 -0.0061271101 ## HI-REDUCTION 51 0.000254 0.000070 ## Tracing fn(par, ...) on exit ## [1] 0.0004588363 0.0097410910 0.0110143453 ## Tracing fn(par, ...) on exit ## [1] 5.231265e-05 -6.491268e-03 -1.841746e-03 ## HI-REDUCTION 53 0.000118 0.000052 ## Tracing fn(par, ...) on exit ## [1] 0.0001368742 0.0108187880 -0.0025708660 ## Tracing fn(par, ...) on exit ## [1] 2.755658e-05 -4.596935e-03 1.463417e-03 ## HI-REDUCTION 55 0.000070 0.000028 ## Tracing fn(par, ...) on exit ## [1] 0.0003664145 -0.0186627497 -0.0024573874 ## Tracing fn(par, ...) on exit ## [1] 3.709448e-06 1.015222e-03 9.449464e-04 ## HI-REDUCTION 57 0.000052 0.000004 ## Tracing fn(par, ...) on exit ## [1] 0.0000626558 0.0029095551 0.0042501093 ## Tracing fn(par, ...) on exit ## [1] 1.745326e-05 -4.141062e-03 -3.187824e-04 ## HI-REDUCTION 59 0.000028 0.000004 ## Tracing fn(par, ...) on exit ## [1] 4.267097e-06 1.471095e-03 -8.372525e-04 ## Tracing fn(par, ...) on exit ## [1] 2.081740e-07 -4.591230e-05 -2.620853e-04 ## LO-REDUCTION 61 0.000017 0.000000 ## Tracing fn(par, ...) on exit ## [1] 2.912577e-05 5.110372e-03 1.001644e-03 ## Tracing fn(par, ...) on exit ## [1] 3.342713e-06 -1.828204e-03 1.132410e-05 ## HI-REDUCTION 63 0.000004 0.000000 ## Tracing fn(par, ...) on exit ## [1] 1.263743e-05 -2.889338e-03 -1.195708e-03 ## Tracing fn(par, ...) on exit ## [1] 5.052935e-07 3.908218e-05 4.097829e-04 ## HI-REDUCTION 65 0.000003 0.000000 ## Tracing fn(par, ...) on exit ## [1] 3.373195e-06 1.821374e-03 1.363736e-04 ## Tracing fn(par, ...) on exit ## [1] 8.441476e-07 -9.158093e-04 4.258647e-05 ## HI-REDUCTION 67 0.000001 0.000000 ## Tracing fn(par, ...) on exit ## [1] 8.593883e-07 9.089792e-04 1.051112e-04 ## Tracing fn(par, ...) on exit ## [1] 2.214113e-07 -4.596122e-04 5.821765e-05 ## HI-REDUCTION 69 0.000001 0.000000 ## Tracing fn(par, ...) on exit ## [1] 1.426297e-06 -5.446067e-04 -6.136505e-04 ## Tracing fn(par, ...) on exit ## [1] 8.249310e-08 -1.068400e-04 1.539246e-04 ## HI-REDUCTION 71 0.000000 0.000000 ## Tracing fn(par, ...) on exit ## [1] 1.772082e-07 3.068599e-04 -1.663784e-04 ## Tracing fn(par, ...) on exit ## [1] 4.973221e-08 1.152418e-04 -1.102294e-04 ## LO-REDUCTION 73 0.000000 0.000000 ## Tracing fn(par, ...) on exit ## [1] 2.834551e-07 5.431411e-05 3.057805e-04 ## Tracing fn(par, ...) on exit ## [1] 4.372056e-08 -2.085570e-05 -1.201188e-04 ## Exiting from Nelder Mead minimizer ## 75 function evaluations used ## $par ## [1] -0.0000208557 -0.0001201188 ## ## $value ## [1] 4.372056e-08 ## ## $counts ## function gradient ## 75 NA ## ## $convergence ## [1] 0 ## ## $message ## NULL untrace(f1) It is possible that the Nelder–Mead algorithm converges to points that are not local optima. See Example 2.9 in the GH book. Questions: 1. How is the initial simplex constructed? 2. How to set the stopping criteria? Advanced methods are available in R package . 3.2.4 Optimization with R See conversation with John Nash about r optim and r optimx. 3.3 MM Algorithm The MM algorithm may be viewed as philosophy for optimization algorithms. The EM algorithm is a special case. An MM algorithm operates by creating a surrogate function that majorizes (minorizes) the objective function. When the surrogate function is optimized, the objective function is driven downhill (uphill). The MM can stand for majorization-minimization or minorization-maximization. The algorithm may avoid matrix inversion, linearize an optimization problem, conveniently deal with equality and inequality constraints, and solve a non-differentiable problem by iteratively solving smooth problems. A function \\(g(\\theta \\mid \\theta^s)\\) is said to majorize the function \\(f(\\theta)\\) at \\(\\theta^s\\) if \\[ f(\\theta^s) = g(\\theta^s \\mid \\theta^s), \\] and \\[ f(\\theta) \\leq g(\\theta \\mid \\theta^s) \\] for all \\(\\theta\\). The descent property of the MM algorithm is easy to see. Let \\[ \\theta^{s+1} = \\arg\\min_\\theta g(\\theta \\mid \\theta^s). \\] It follows that \\[\\begin{align*} f(\\theta^{s+1}) \\leq g(\\theta^{s+1} \\mid \\theta^s) \\leq g(\\theta^{s} \\mid \\theta^s) = f(\\theta^s). \\end{align*}\\] The strict inequality holds unless \\(g(\\theta^{s+1} \\mid \\theta^s)=g(\\theta^{s} \\mid \\theta^s)\\) and \\(f(\\theta^{s+1})= g(\\theta^{s+1} \\mid \\theta^s)\\). Therefore, by alternating between the majorization and the minimization steps, the objective function is monotonically decreasing and thus its convergence is guaranteed. par(mar=c(2.5, 2.5, 0.1, 0.1), mgp=c(1.5, 0.5, 0)) f &lt;- function(x) abs(x - 1) + abs(x - 3) + abs(x - 4) + abs(x - 8) + abs(x - 10) curve(f(x), 0, 12) g &lt;- function(x) (x - 5.5)^2 + 15.75 curve(g(x), 0, 12, add = TRUE, col=&quot;blue&quot;) Inequalities are used to devise MM algorithms. Jensen’s inequality: for a convex function \\(f(x)\\), \\[ f(E(X)) \\leq E(f(X)). \\] Convexity inequality: for any \\(\\lambda \\in [0,1]\\), \\[ f(\\lambda x_1 + (1-\\lambda)x_2) \\leq \\lambda f(x_1) + (1-\\lambda)f(x_2). \\] Cauchy-Schwarz inequality. Supporting hyperplanes. Arithmetic-Geometric Mean Inequality. 3.4 An Example: LASSO with Coordinate Descent In a linear regression setting, where \\(Y\\) is the response vector and \\(X\\) is the design matrix. Minimize objective function \\[ \\min_{\\beta \\in R^p}\\left\\{\\frac{1}{2n}\\|Y - X \\beta\\|^2 + \\sum_{j = 1}^p p_{\\lambda}(|\\beta_j|)\\right\\}, \\] where \\(\\|\\cdot\\|\\) denotes the \\(L_2\\)-norm, and \\(p_{\\lambda}(\\cdot)\\) is a penalty function indexed by the regularization parameter \\(\\lambda \\geq 0\\). It is often assumed that the covariates are centered and standardized such that the coefficients become comparable. Common penalties: \\(L_0\\) penalty (subset selection) and \\(L_2\\) penalty (ridge regression). Bridge or \\(L_\\gamma\\) penalty, \\(\\gamma &gt;0\\) \\(L_1\\) penalty or Lasso SCAD penalty MCP penalty Group penalties Bilevel penalties LASSO stands for ``least absolute shrinkage and selection operator’’. There are two equivalent definitions. minimize the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant: \\[ \\hat{\\beta}=\\arg\\min\\left\\{\\frac{1}{2n}\\|Y- X \\beta\\|^2\\right\\} \\text{ subject to } \\sum_{j}|\\beta_j| \\leq t. \\] minimize the penalized sum of squares: \\[ \\hat{\\beta}=\\arg\\min\\left\\{\\frac{1}{2n}\\|Y- X\\beta\\|^2 + \\lambda\\sum_{j}|\\beta_j|\\right\\}. \\] Because of the nature of \\(L_1\\) penalty or constraint, Lasso can estimate some coefficients as exactly \\(0\\) and hence performs variable selection. It enjoys some of the favorable properties of both subset selection and ridge regression, producing interpretable models and exhibiting the stability of ridge regression. A solution path for \\(\\lambda\\in[\\lambda_{\\min},\\lambda_{\\max}]\\) is \\[ \\{\\widehat{\\beta}_{n}(\\lambda): \\lambda\\in[\\lambda_{\\min},\\lambda_{\\max}]\\}. \\] For a given \\(\\lambda\\), the coordinate descent algorithm minimize the objective function with respect to \\(\\beta_j\\) given current values of \\(\\tilde\\beta_k\\), \\(k \\ne j\\). Define \\[ L_j(\\beta_j; \\lambda) = \\frac{1}{2n}\\sum_{i=1}^n \\left(y_i - \\sum_{k\\ne j} x_{ik}\\tilde\\beta_k - x_{ij} \\beta_j\\right)^2 + \\lambda |\\beta_j|. \\] Let \\(\\tilde y_{ij} = \\sum_{k\\ne j} x_{ik}\\tilde\\beta_k\\), \\(\\tilde r_{ij} = y_i - \\tilde y_{ij}\\), and \\(\\tilde z_j = n^{-1} \\sum_{i=1}^n x_{ij} \\tilde r_{ij}\\). Note that \\(\\tilde r_{ij}\\)’s are the partial residual with respect to the \\(j\\)th covariate. Assuming that the covariates are centered and standardized such that \\(\\sum_{i=1}^{n}x_{ij}=0\\) and \\(\\sum_{i=1}^{n}x_{ij}^2=n\\) for all \\(1\\leq j \\leq p\\), the standardized covariates and completion of squares lead to \\[ L_j(\\beta_j; \\lambda) = \\frac{1}{2}(\\beta_j - \\tilde z_j)^2 + \\lambda |\\beta_j| + \\frac{1}{2n} \\sum_{i=1}^n \\tilde r_{ij}^2 - \\frac{1}{2} \\tilde z_j^2. \\] This is just a univariate quadratic programming problem. The solution is \\[ \\tilde \\beta_j = S(\\tilde z_{j}; \\lambda) \\] where \\(S(\\cdot; \\lambda)\\) is the soft-threshold operator \\[ S(z; \\lambda) = \\mathrm{sgn}(z) (|z| - \\lambda)_+ = \\begin{cases} z - \\lambda, &amp; z &gt; \\lambda,\\\\ 0, &amp; |z| \\le \\lambda,\\\\ z + \\lambda, &amp; z &lt; -\\lambda.\\\\ \\end{cases} \\] The last question is, how do we choose \\(\\lambda\\)? Cross-validation or generalized cross-validation. 3.5 Exercises 3.5.1 Cauchy with unknown location. Consider estimating the location parameter of a Cauchy distribution with a known scale parameter. The density function is \\[\\begin{align*} f(x; \\theta) = \\frac{1}{\\pi[1 + (x - \\theta)^2]}, \\quad x \\in R, \\quad \\theta \\in R. \\end{align*}\\] Let \\(X_1, \\ldots, X_n\\) be a random sample of size \\(n\\) and \\(\\ell(\\theta)\\) the log-likelihood function of \\(\\theta\\) based on the sample. Show that \\[\\begin{align*} \\ell(\\theta) &amp;= -n\\ln \\pi - \\sum_{i=1}^n \\ln [1+(\\theta-X_i)^2], \\\\ \\ell&#39;(\\theta) &amp;= -2 \\sum_{i=1}^n \\frac{\\theta-X_i}{1+(\\theta-X_i)^2}, \\\\ \\ell&#39;&#39;(\\theta) &amp;= -2 \\sum_{i=1}^n \\frac{1-(\\theta-X_i)^2}{[1+(\\theta-X_i)^2]^2}, \\\\ I_n(\\theta) &amp;= \\frac{4n}{\\pi} \\int_{-\\infty}^\\infty \\frac{x^2\\,\\mathrm{d}x}{(1+x^2)^3} = n/2, \\end{align*}\\] where \\(I_n\\) is the Fisher information of this sample. Set the random seed as \\(909\\) and generate a random sample of size \\(n = 10\\) with \\(\\theta = 5\\). Implement a loglikelihood function and plot against \\(\\theta\\). Find the MLE of \\(\\theta\\) using the Newton–Raphson method with initial values on a grid starting from \\(-10\\) to \\(30\\) with increment \\(0.5\\). Summarize the results. Improved the Newton–Raphson method by halving the steps if the likelihood is not improved. Apply fixed-point iterations using \\(G(\\theta)=\\alpha \\ell&#39;(\\theta) + \\theta\\), with scaling choices of \\(\\alpha \\in \\{1, 0.64, 0.25\\}\\) and the same initial values as above. First use Fisher scoring to find the MLE for \\(\\theta\\), then refine the estimate by running Newton-Raphson method. Try the same starting points as above. Comment on the results from different methods (speed, stability, etc.). 3.5.2 Many local maxima Consider the probability density function with parameter \\(\\theta\\): \\[\\begin{align*} f(x; \\theta) = \\frac{1 - \\cos(x - \\theta)}{2\\pi}, \\quad 0\\le x\\le 2\\pi, \\quad \\theta \\in (-\\pi, \\pi). \\end{align*}\\] A random sample from the distribution is x &lt;- c(3.91, 4.85, 2.28, 4.06, 3.70, 4.04, 5.46, 3.53, 2.28, 1.96, 2.53, 3.88, 2.22, 3.47, 4.82, 2.46, 2.99, 2.54, 0.52) Find the the log-likelihood function of \\(\\theta\\) based on the sample and plot it between \\(-\\pi\\) and \\(\\pi\\). Find the method-of-moments estimator of \\(\\theta\\). That is, the estimator \\(\\tilde\\theta_n\\) is value of \\(\\theta\\) with \\[\\begin{align*} \\mathbb{E}(X \\mid \\theta) = \\bar X_n, \\end{align*}\\] where \\(\\bar X_n\\) is the sample mean. This means you have to first find the expression for \\(\\mathbb{E}(X \\mid \\theta)\\). Find the MLE for \\(\\theta\\) using the Newton–Raphson method initial value \\(\\theta_0 = \\tilde\\theta_n\\). What solutions do you find when you start at \\(\\theta_0 = -2.7\\) and \\(\\theta_0 = 2.7\\)? Repeat the above using 200 equally spaced starting values between \\(-\\pi\\) and \\(\\pi\\). Partition the values into sets of attraction. That is, divide the set of starting values into separate groups, with each group corresponding to a separate unique outcome of the optimization. 3.5.3 Modeling beetle data The counts of a floor beetle at various time points (in days) are given in a dataset. beetles &lt;- data.frame( days = c(0, 8, 28, 41, 63, 69, 97, 117, 135, 154), beetles = c(2, 47, 192, 256, 768, 896, 1120, 896, 1184, 1024)) A simple model for population growth is the logistic model given by \\[ \\frac{\\mathrm{d}N}{\\mathrm{d}t} = r N(1 - \\frac{N}{K}), \\] where \\(N\\) is the population size, \\(t\\) is time, \\(r\\) is an unknown growth rate parameter, and \\(K\\) is an unknown parameter that represents the population carrying capacity of the environment. The solution to the differential equation is given by \\[ N_t = f(t) = \\frac{K N_0}{N_0 + (K - N_0)\\exp(-rt)}, \\] where \\(N_t\\) denotes the population size at time \\(t\\). Fit the population growth model to the beetles data using the Gauss-Newton approach, to minimize the sum of squared errors between model predictions and observed counts. Show the contour plot of the sum of squared errors. In many population modeling application, an assumption of lognormality is adopted. That is , we assume that \\(\\log N_t\\) are independent and normally distributed with mean \\(\\log f(t)\\) and variance \\(\\sigma^2\\). Find the maximum likelihood estimators of \\(\\theta = (r, K, \\sigma^2)\\) using any suitable method of your choice. Estimate the variance your parameter estimates. 3.5.4 Coordinate descent for penalized least squares Consider the penalized least squares problem with \\(L_1\\) penalty (LASSO). Verify the soft-threshold solution. Find \\(\\lambda_{\\max}\\) such that for any \\(\\lambda &gt; \\lambda_\\max\\), the solution is \\(\\beta = 0\\). Write a function to implement the soft-threshold solution for a given input z and lambda. Write a function pen_ls to implement the coordinate descent method for LASSO solution. The inputs of the function should include a response vector y, a model matrix xmat (with pre-standardized columns), and a penalty parameter lambda. The output is a vector of estimated \\(\\beta\\). Test your pen_ls on a simulated dataset generated for a fixed \\(\\lambda\\). gen_data &lt;- function(n, b, sigma = 1) { p &lt;- length(b) x &lt;- matrix(rnorm(n * p), n, p) colnames(x) &lt;- paste0(&quot;x&quot;, 1:p) y &lt;- c(x %*% b) + rnorm(n, sd = sigma) return(data.frame(y, x)) } n &lt;- 200 b &lt;- c(1, -1, 2, rep(0, 7)) set.seed(920) dat &lt;- gen_data(n, b) Plot a solution path for a sequence of \\(\\lambda\\) values from \\(\\lambda_\\max\\) to zero. References "],["em-algorithm.html", "Chapter 4 EM Algorithm 4.1 Introduction 4.2 EM Algorithm 4.3 Example: Clustering by EM 4.4 Variants of EM 4.5 Standard Errors 4.6 Acceleration 4.7 Example: Hidden Markov Model 4.8 Exercises", " Chapter 4 EM Algorithm 4.1 Introduction The EM algorithm is an application of the MM algorithm. Proposed by Dempster, Laird, and Rubin (1977), it is one of the pillars of modern computational statistics. Every EM algorithm has some notion of missing data. Setup: Complete data \\(X = (Y, Z)\\), with density \\(f(x | \\theta)\\). Observed data \\(Y\\). Some function \\(t(X) = Y\\) collapses \\(X\\) into \\(Y\\). Missing data \\(Z\\). The definition of \\(X\\) is left up to the creativity of the statistician. The general idea is to choose \\(X\\) so that the MLE is trivial for complete data. 4.2 EM Algorithm The EM algorithm iterates between the two steps until convergence: E-step: compute the conditional expectation \\[\\begin{equation*} Q(\\theta | \\theta_n) = E [\\log f(X | \\theta) | Y = y, \\theta_n], \\end{equation*}\\] where \\(\\theta_n\\) is the current estimate of \\(\\theta\\). Note that expectation needed is for functions of missing data \\(Z\\) instead of \\(Z\\) itself, although sometimes it can be \\(Z\\) itself. M-step: maximize \\(Q(\\theta | \\theta_n)\\) with respect to \\(\\theta\\) to obtain the new estimate \\(\\theta_{n + 1}\\). Ascent property: Let \\(g(y | \\theta)\\) be the observed likelihood. Then the EM algorithm enjoys the ascent property: \\[\\begin{equation*} \\log g(y | \\theta_{n + 1}) \\ge \\log g(y | \\theta_n). \\end{equation*}\\] It is sufficient to show the minorization inequality: \\[\\begin{equation*} \\log g(y | \\theta) \\ge Q(\\theta | \\theta_n) + \\log g(y | \\theta_n) - Q(\\theta_n | \\theta_n). \\end{equation*}\\] Information inequality: For densities \\(h_1\\) and \\(h_2\\) with respect to measure \\(\\mu\\), \\(E_{h_1} \\log h_1(X) \\ge E_{h_1} \\log h_2(X)\\) with equality only if \\(h_1 = h_2\\) almost everywhere relative to \\(\\mu\\). To prove the ascent property, let \\(h_1(x | y, \\theta) = f(x|\\theta) / g(y | \\theta)\\) and \\(h_2(x | y, \\theta_n) = f(x | \\theta_n) / g(y | \\theta_n)\\) be conditional densities of \\(X\\) on the set \\(\\{x: t(x) = y\\}\\) with respect to some measure \\(\\mu_y\\). 4.3 Example: Clustering by EM Suppose that \\(y_1, \\ldots, y_n\\) form a random sample from a mixture density \\(h(y) = \\sum_{j=1}^k \\pi_j h_j(y | \\theta)\\), where \\(\\pi_j &gt; 0\\), \\(j = 1, \\ldots, n\\), and \\(\\sum_{j=1}^k \\pi_j = 1\\), \\(h_j\\) is the density function of group \\(j\\) with parameter \\(\\theta\\). For example, each group density can be normal with common variance \\(\\sigma^2\\) but with group specific mean \\(\\mu_j\\)’s. Problem: estimate the parameters \\(\\pi_j\\)’s and \\(\\theta\\). Missing data: let \\(z_{ij}\\) be the indicator such that \\(z_{ij} = 1\\) if observation \\(y_i\\) is from group \\(j\\), and zero otherwise. Complete data likelihood: \\[ \\sum_{i=1}^n \\sum_{j=1}^k z_{ij}[\\log \\pi_j + \\log h_j(y_i | \\theta)]. \\] E-step: conditional expectation of \\(z_{ij}\\), \\(w_{ij}\\), given current \\(\\pi_j\\)’s and \\(\\theta\\). By Bayes’ rule, \\[\\begin{equation*} w_{ij} = \\frac{\\pi_j h_j(y_i | \\theta)}{\\sum_{l=1}^k \\pi_l h_l(y_i | \\theta)} \\end{equation*}\\] M-step: with missing values filled by their conditional expectations \\(w_{ij}\\), the maximization step separates \\(\\pi\\) from \\(\\theta\\). Question: what if there is no closed form E-step or M-step? 4.4 Variants of EM 4.4.1 MCEM Classroom examples may give an impression that the E-step consists of replacing the missing data by their conditional expectations given the observed data at current parameter values. Although in many examples this may be the case as the complete loglikelihood is a linear function of the missing data \\(Z\\), it is not quite so in general. When the E-step has no closed-form, it can be approximated by a Monte Carlo process, and this variant of the EM algorithm is known as the Monte Carlo EM (MCEM) (Wei and Tanner 1990). The Monte Carlo E-step goes as the following. The sample size can be different from iteration to iteration; smaller sample size may by sufficient earlier on but larger sample sizes are needed in the vicinity of the convergence to control the Monte Carlo error. Importance sampling can be used as well. MCEM routines need to address two challenges (Levine and Casella 2001) (1) how do we minimize the computational cost in obtaining an sample? and (2) how do we choose the Monte Carlo sample size? Rejection sampling and importance sampling can be used for the first. For the second, the number of simulations at iterations in which the change in the parameter value is swamped by Monte Carlo error needs to be increased in an automated way. 4.4.2 ECM The Expectation Conditional Maximization (ECM) algorithm (Meng and Rubin 1993) is a class of generalized EM (GEM) algorithms (Dempster, Laird, and Rubin 1977), where the M-step is only partially implemented, with the new estimate improving the likelihood found in the E-step, but not necessarily maximizing it. The ECM algorithm replaces the M-step of the EM algorithm with several computationally simpler conditional maximization (CM) steps. Each of these CM-steps maximizes the \\(Q\\)-function found in the preceding E-step subject to constraints on \\(\\theta\\), where the collection of all constraints is such that the maximization is over the full parameter space of \\(\\theta\\). It is essentially coordinate ascend! A CM-step might be in closed form or it might itself require iteration, but because the CM maximizations are over smaller dimensional spaces, often they are simpler, faster, and more stable than the corresponding full maximizations called for on the M-step of the EM algorithm, especially when iteration is required. The ECM algorithm typically converges more slowly than the EM in terms of number of iterations, but can be faster in total computer time. More importantly, the ECM algorithm preserves the appealing convergence properties of the EM algorithm, such as its monotone convergence. 4.5 Standard Errors 4.5.1 Supplemental EM (SEM) Meng and Rubin (1991) proposed a general automated algorithm named SEM to obtain numerically stable asymptotic variance matrix of the estimator from the EM algorithm. The method uses the fact that the rate of convergence of EM is governed by the fractions of the missing information to find the increased variability due to missing information to add to the complete-data variance matrix. Keeping the notation of \\(X = (Y, Z)\\), from the factorization \\[ f(X | \\theta) = g(Y | \\theta) k(Z | Y; \\theta), \\] where \\(f\\), \\(g\\), and \\(k\\) are the joint, marginal and conditional density of their arguments, respectively. The observed loglikelihood is the difference between the complete loglikelihood and the conditional loglikelihood \\[ L(\\theta | Y) = L(\\theta | X) - \\log k(Z | Y; \\theta). \\] Taking the second derivatives, averaging over \\(k(Z | Y; \\theta)\\), and evaluate at the MLE \\(\\theta = \\theta^*\\), we have \\[ I_o(\\theta^* | Y) = I_{oc} - I_{om}, \\] where \\[ I_o(\\theta | Y) = - \\frac{\\partial^2 \\log g(Y | \\theta)}{\\partial\\theta\\partial\\theta^{\\top}} \\] is the observed information matrix, \\[ I_{oc} = E[I_o(\\theta | Y) \\vert Y, \\theta] \\big\\vert_{\\theta = \\theta^*} \\] the conditional expectation of the complete-data observed information given the observed data, and \\[ I_{om} = E\\left[ - \\frac{\\partial^2 \\log k(Z | Y; \\theta)}{\\partial\\theta\\partial\\theta^2} \\big\\vert Y, \\theta\\right] \\big\\vert_{\\theta = \\theta^*} \\] is viewed as the missing information. The interpretation is appealing: \\[ \\mbox{observed information} = \\mbox{complete information} - \\mbox{missing information} \\] which is known as the ``missing information principal’’. The observed information can be written as \\[ I_o(\\theta^* | Y) = (I - R) I_{oc}, \\] where \\(R = I_{om} I_{oc}^{-1}\\). It has been shown that the convergence rate of the EM algorithm is \\(R\\) (Dempster, Laird, and Rubin 1977). If an estimate of \\(R\\) is available, the target variance matrix can be estimated using \\[ I_{oc}^{-1} (I - R)^{-1} = I_{oc}^{-1} + I_{oc}^{-1}R (I - R)^{-1}. \\] The SEM algorithm needs to evaluate \\(I_{oc}^{-1}\\) and \\(R\\). Evaluation of \\(I_{oc}\\) is simplified if \\(X\\) is from an exponential family. It can be obtained simply by substituting the conditional expectation of the sufficient statistics \\(S(Y)\\) found at the last E-step. Non-exponential family cases can be handled by linearization of the complete loglikelihood in terms of \\(S(Y)\\). The computation of \\(R\\) is done numerically. Each element of \\(R\\) is estimated by the component-wise rate of convergence of a ``forced EM’’. Let \\(r_{ij}\\) be the \\((i,j)\\)th element of \\(R\\). Let \\[ \\theta^{(t)}(i) = (\\theta_1^*, \\ldots, \\theta_{i-1}^*, \\theta_i^{(t)}, \\theta_{i+1}^*, \\ldots, \\theta_d^*), \\] that is, only the \\(i\\)th component in the \\(d\\)-dimensional vector \\(\\theta^{t}(i)\\) is active in the sense that other components are fixed at their MLE’s. Given \\(\\theta^*\\) and \\(\\theta^{(t)}\\), one iteration of the EM algorithm can be run to obtain \\(\\tilde\\theta^{(t+1)}(i) = M\\big(\\theta^{(t)}(i)\\big)\\). Then, obtain \\[ r_{ij}^{(t)} = \\frac{\\tilde\\theta_j^{(t+1)}(i) - \\theta_j^*}{\\theta_i^{(t)} - \\theta_i^*}, \\] for \\(j = 1, \\ldots, d\\). This rate approximates the slope of the map of \\(\\theta^{(t + 1)} = M(\\theta^{(t)})\\). 4.5.2 Direct Calculation of the Information Matrix Oakes (1999) derived an explicit formula for the observed information matrix in terms of derivatives of the \\(Q\\) function (conditional expectation of the complete-data loglikelihood given the observed data) invoked by the EM algorithm. Start from the fundamental identity: \\[\\begin{equation} L(\\phi, X) = Q(\\phi&#39; | \\phi) - E_{X\\mid Y,\\phi} \\log k(X \\mid Y; \\phi&#39;) \\tag{4.1} \\end{equation}\\] where \\(Q(\\phi&#39; \\mid \\phi) = E_{X \\mid Y,\\phi} L_0(\\phi&#39;, X)\\), and \\(L_0\\) is the complete-data loglikelihood. Assuming that the usual exchange of expectation with respect to \\(X\\) and differentiation in \\(\\phi\\) hold for \\(\\log k(X | Y, \\phi)\\). This gives two identities \\[ E_{X\\mid Y,\\phi} \\frac{\\partial\\log k(X\\mid Y; \\phi)}{\\partial \\phi} = 0 \\] and \\[ E_{X\\mid Y,\\phi} \\frac{\\partial^2 \\log k(X\\mid Y; \\phi)}{\\partial\\phi^2} + E_{X\\mid Y,\\phi} \\frac{\\partial \\log k(X\\mid Y; \\phi)}{\\partial \\phi} \\left[\\frac{\\partial \\log k(X\\mid Y; \\phi)}{\\partial \\phi}\\right]^{\\top}. \\] Differentiation of (4.1) in \\(\\phi&#39;\\) gives \\[\\begin{equation} \\frac{\\partial L}{\\partial \\phi} = \\frac{\\partial Q(\\phi&#39; | \\phi)}{\\partial \\phi&#39;} - E_{X\\mid Y, \\phi} \\frac{\\partial \\log k(X\\mid Y, \\phi&#39;)}{\\partial \\phi&#39;} . \\tag{4.2} \\end{equation}\\] Substituting \\(\\phi\\) with \\(\\phi&#39;\\) makes the second term vanish, which leads to \\[ \\frac{\\partial L}{\\partial \\phi} = \\left\\{\\frac{\\partial Q(\\phi&#39; | \\phi)}{\\partial \\phi&#39;} \\right\\}_{\\phi = \\phi&#39;}. \\] Differentiation of (4.2) in \\(\\phi&#39;\\) and \\(\\phi\\) gives respectively \\[ \\frac{\\partial^2 L}{\\partial \\phi&#39;^2} = \\frac{\\partial^2 L}{\\partial \\phi&#39;^2} - E_{X\\mid Y, \\phi} \\frac{\\partial^2 \\log k(X\\mid Y, \\phi&#39;)}{\\partial \\phi&#39;^2}, \\] and \\[ 0 = \\frac{\\partial^2 Q(\\phi&#39;|\\phi)}{\\partial \\phi&#39;\\partial \\phi} - E_{X\\mid Y, \\phi} \\frac{\\partial \\log k(X\\mid Y, \\phi&#39;)}{\\partial \\phi&#39;} \\left[\\frac{\\partial \\log k(X\\mid Y, \\phi)}{\\partial \\phi} \\right]^{\\top}. \\] Substituting \\(\\phi = \\phi&#39;\\), adding the two equations and using the information identity give \\[ \\frac{\\partial^2 L}{\\partial \\phi^2} = \\left\\{\\frac{\\partial^2 Q(\\phi&#39;|\\phi)}{\\partial \\phi&#39;^2} + \\frac{\\partial^2 Q(\\phi&#39;|\\phi)}{\\partial \\phi&#39;\\partial \\phi} \\right\\}_{\\phi&#39; = \\phi}, \\] which is valid for all \\(\\phi\\). The second term is the ``missing information’’ due to the fact that only \\(Y\\) instead of \\(X\\) is observed. If the complete data is from an exponential family, the second term reflects the sensitivity of the imputed complete-data sufficient statistic to changes in hypothesized parameter value. 4.6 Acceleration Can we obtain fast convergence without sacrificing the stability of EM? 4.7 Example: Hidden Markov Model A hidden Markov model (HMM) is a dependent mixture model. The model consists of two parts: 1) a Markov process for the unobserved state process \\(\\{S_t: t = 1, 2, \\ldots\\}\\); and 2) a state-dependent process for the observed data \\(\\{X_t: t = 1, 2, \\ldots\\}\\) such that when \\(S_t\\) is known, the distribution of \\(X_t\\) depends on \\(S_t\\) only and not on previous states or observations. It can be characterized by \\[\\begin{align} \\Pr(S_t \\mid S_1, \\ldots, S_{t - 1}) &amp;= \\Pr(S_t \\mid S_{t-1}),\\quad t = 2, 3, \\ldots, \\\\ \\Pr(X_t \\mid S_1, \\ldots, S_t; X_1, \\ldots, X_{t-1}) &amp;= \\Pr(X_t \\mid S_t), \\quad t = 1, 2, \\ldots. \\end{align}\\] HMMs have a wide range of applications. Suppose that process \\(S_t\\) has \\(m\\) states. Let \\(\\delta\\) be the parameters of the initial distribution of \\(S_t\\). Let \\(\\Gamma\\) be the probability transition matrix of \\(S_t\\). Let \\(\\theta\\) be the parameter vector in \\(\\Pr(X_t | S_t)\\). Given the observed data \\(\\{x_t: t = 1, \\ldots, T\\}\\), these parameters can be estimated by an application of the EM algorithm where the unobserved states \\(\\{s_t: t = 1, \\ldots, T\\}\\) are treated as missing data. To devise the EM algorithm, we need the complete data loglikelihood. Let \\(u_j(t) = I(s_t = j)\\), \\(t = 1, \\ldots, T\\), \\(j = 1, \\ldots, m\\), and \\(v_{jk}(t) = I(s_{t-1} = j, s_t = k)\\), \\(t = 2, \\ldots, T\\), and \\(j, k \\in \\{1, \\ldots, m\\}\\). The complete data loglikelihood is \\[\\begin{align*} &amp;{=} \\log p(s_1, \\ldots, s_T, x_1, \\ldots, x_T)\\\\ &amp;= \\log \\delta_{s_1} \\prod_{t=2}^T \\Gamma_{s_{t-1}, s_t} \\prod_{t=1}^T p(x_t | s_t; \\theta)\\\\ &amp;= \\log \\delta_{s_1} + \\sum_{t=2}^T \\log \\Gamma_{s_{t-1}, s_t} + \\sum_{t=1}^T \\log p(x_t | s_t; \\theta)\\\\ &amp;= \\sum_{i=1}^m u_j(1) \\log \\delta_j + \\sum_{j=1}^m \\sum_{k=1}^m \\sum_{t=2}^T v_{jk}(t) \\log \\Gamma_{jk} + \\sum_{j=1}^m \\sum_{t=1}^T u_j(t) \\log p(x_t | s_t = j; \\theta) \\end{align*}\\] In the E-step, quantities \\(u_j(t)\\) and \\(v_{jk}(t)\\) needs be replaced with their conditional expectations given \\(\\{x_t: t = 1, \\ldots, T\\}\\). Define row vector \\(\\alpha(t)\\) as \\[ \\alpha(t) = \\delta \\prod_{r=2}^t \\Gamma P(x_r), \\] where \\(P(x_r | \\theta) = diag[p(x_r | 1; \\theta), \\ldots, p(x_r | m; \\theta)]\\). This is indeed a probability vector, known as the forward probability, because the \\(j\\)th component is \\(\\alpha_j(t) = p(x_1, \\ldots, x_t, s_t = j)\\). Define vector \\(\\beta(t)\\) as \\[ \\beta(t) = \\prod_{r = t + 1}^T \\Gamma P(x_r) \\mathbf{1}, \\] with the convention that an empty product is the identity matrix, where \\(\\mathbf{1}\\) is the column vector of ones. This is also a probability vector, known as the backward probability, because the \\(j\\)th component is \\(\\beta_j(t) = p(x_{t+1}, \\ldots, x_T | s_t = j)\\). The forward probabilities are affected by the initial probabilities \\(\\delta\\), and the model does not need to assume stationarity of \\(S_t\\). The backward probabilities, however, are not affected by stationarity of \\(S_t\\). It follows that for all \\(t \\in \\{1, \\ldots, T\\}\\) and \\(j \\in \\{1, \\ldots, m\\}\\), \\[ \\alpha_j(t) \\beta_j(t) = p(x_1, \\ldots, x_T, s_t = j). \\] Consequently, \\(\\alpha(t) \\beta(t) = p(x_1, \\ldots, x_T) = L_T\\) for each \\(t\\). It can be verified that, for \\(t \\in \\{1, \\ldots, T\\}\\), \\[\\begin{equation} p(S_t = j | x_1, \\ldots, x_T) = \\alpha_j(t) \\beta_j(t) / L_T, \\tag{4.3} \\end{equation}\\] and that, for \\(t \\in \\{2, \\ldots, T\\}\\), \\[\\begin{equation} p(s_{t - 1} = j, s_t = k | x_1, \\ldots, x_T) = \\alpha_j(t - 1) \\Gamma_{jk} p(x_t | k; \\theta) \\beta_k(t) / L_T. \\tag{4.4} \\end{equation}\\] Equations (4.3) and (4.4), respectively, give the needed conditional expectation in the E-step for \\(u_j(t)\\) and \\(v_{jk}(t)\\) given the observations \\(\\{x_t: t = 1, \\ldots, T\\}\\). In the M-step, the maximization with respect to three sets of parameters \\(\\delta\\), \\(\\Gamma\\), and \\(\\theta\\) can be done separately; each term in the summation depends only on one set. Maximization with respect to \\(\\delta\\) and \\(\\Gamma\\) has closed-form solution, while maximization with respect to \\(\\theta\\) needs to be done numerically in general. 4.8 Exercises 4.8.1 Finite mixture regression Given \\(n\\) independent observations of the response \\(Y \\in \\mathbb{R}\\) and predictor \\(\\mathbf{X} \\in \\mathbb{R}^p\\), multiple linear regression models are commonly used to explore the conditional mean structure of \\(Y\\) given \\(\\mathbf{X}\\). However, in many applications, the underlying assumption that the regression relationship is homogeneous across all the observations \\((y_1, \\mathbf{x}_1),\\ldots,(y_n, \\mathbf{x}_n)\\) can be easily violated. Instead, the observations may form several distinct clusters indicating mixed relationships between the response and the predictors. Such heterogeneity can be more appropriately modeled by a finite mixture regression model, consisting of, say, \\(m\\) homogeneous groups/components. Suppose the density of \\(y_i\\) (conditional on \\(\\mathbf{x}_i\\)), is given by \\[\\begin{eqnarray} f(y_i\\mid \\mathbf{x}_i,\\boldsymbol{\\Psi})= \\sum_{j=1}^{m} \\pi_{j}\\phi(y_i;\\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}_{j}, \\sigma^2),\\qquad i=1,\\ldots,n, \\tag{4.5} \\end{eqnarray}\\] where \\(\\pi_j\\)s are called mixing proportions, \\(\\boldsymbol{\\beta}_j\\) is the regression coefficient vector for the \\(j\\)th group, \\(\\phi(\\cdot\\:;\\mu,\\sigma^2)\\) denotes the density function of \\(N(\\mu,\\sigma^2)\\), and \\(\\boldsymbol{\\Psi}=(\\pi_1,\\boldsymbol{\\beta}_1,\\ldots,\\pi_m,\\boldsymbol{\\beta}_m,\\sigma)^T\\) collects all the unknown parameters. Maximum likelihood estimation is commonly used to infer the unknown arameter \\(\\boldsymbol{\\Psi}\\) in (4.5), i.e., \\[\\begin{equation} \\hat{\\boldsymbol{\\Psi}}_{\\mbox{mle}}=\\arg\\max_{\\boldsymbol{\\Psi}}\\sum_{i=1}^n\\log\\left\\{\\sum_{j=1}^m\\pi_j\\phi(y_i;\\textbf{x}_i^{\\top}\\boldsymbol{\\beta}_{j},\\sigma^2)\\right\\}. \\tag{4.6} \\end{equation}\\] The MLE does not have an explicit form and the problem is usually solved by the EM algorithm. Let \\(z_{ij} = 1\\) if \\(i\\)th observation is from \\(j\\)th component} and zero otherwise. Denote the complete data by \\(\\{(\\mathbf{x}_{i}, \\mathbf{z}_{i}, y_{i}); i =1,2,\\ldots,n\\}\\), where the component labels \\(\\mathbf{z}_{i} = (z_{i1}, z_{i2}, \\ldots, z_{im})\\) are not observable or “missing” in practice. The complete log-likelihood can be written as \\[ l_{n}^{c}(\\boldsymbol{\\Psi})=\\sum_{i=1}^{n}\\sum_{j=1}^{m}z_{ij}\\log \\left\\{\\pi_{j}\\phi(y_{i}-\\mathbf{x}_{i}^{\\top}\\boldsymbol{\\beta}_{j};0,\\sigma^{2})\\right\\}. \\] In the E-step, we calculate the conditional expectation of the complete log-likelihood with respect to \\(\\mathbf{z}_{i}\\), and in the M-step, we maximize the obtained conditional expectation with respect to \\(\\boldsymbol{\\Psi}\\). At the \\(k\\)th iteration, the E-Step computes the conditional expectation of \\(l_{n}^{c}(\\boldsymbol{\\Psi})\\): \\[\\begin{align*} Q(\\boldsymbol{\\Psi}\\mid \\boldsymbol{\\Psi}^{(k)}) =\\sum_{i=1}^{n}\\sum_{j=1}^{m}p_{ij}^{(k+1)} \\left\\{\\log\\pi_{j}+\\log\\phi(y_{i}-\\textbf{x}_{i}^{\\top}\\boldsymbol{\\beta}_{j};0,\\sigma^{2})\\right\\}, \\end{align*}\\] where \\[\\begin{align*} p_{ij}^{(k+1)}&amp;=E(z_{ij}\\mid y_{i},\\textbf{x}_{i};\\boldsymbol{\\Psi}^{(k)}) =\\frac{\\pi_{j}^{(k)}\\phi(y_{i}-\\textbf{x}_{i}^{\\top}\\boldsymbol{\\beta}_{j}^{(k)};0,\\sigma^{2^{(k)}})}{\\sum_{j=1}^{m}\\pi_{j}^{(k)}\\phi(y_{i}-\\textbf{x}_{i}^{\\top}\\boldsymbol{\\beta}_{j}^{(k)};0,\\sigma^{2^{(k)}})}. \\end{align*}\\] The M-Step maximizes \\(Q(\\boldsymbol{\\Psi} \\mid \\boldsymbol{\\Psi}^{(k)})\\) to obtain \\[\\begin{align*} \\pi_{j}^{(k+1)} &amp;=\\frac{\\sum_{i=1}^{n}p_{ij}^{(k+1)}}{n}\\\\ \\boldsymbol{\\beta}_{j}^{(k+1)}&amp;=\\left(\\sum_{i=1}^{n}\\textbf{x}_i\\textbf{x}_{i}^{\\top}p_{ij}^{(k+1)}\\right)^{-1}\\left(\\sum_{i=1}^{n}\\textbf{x}_ip_{ij}^{(k+1)}y_i\\right),\\qquad j=1,\\ldots,m;\\\\ \\sigma^{2^{(k+1)}}&amp;=\\frac{\\sum_{j=1}^{m}\\sum_{i=1}^{n}p_{ij}^{(k+1)}(y_{i}-\\textbf{x}_{i}^{\\top}\\boldsymbol{\\beta}_{j}^{(k+1)})^{2}}{n}. \\end{align*}\\] Follow the lecture notes to verify the validity of the provided E- and M-steps. That is, derive the updating rules in the given algorithm based on the construction of an EM algorithm. Implement this algorithm in R with a function regmix_em. The inputs of the functions are y for the response vector, xmat for the design matrix, pi.init for initial values of \\(\\pi_j\\)’s (a vector of \\(K\\times 1\\) vector), beta.init for initial values of \\(\\boldsymbol{\\beta}_j\\)’s (a matrix of \\(p \\times K\\) where \\(p\\) is ncol(xmat) and \\(K\\) is the number of components in the mixture), sigma.init for initial values of \\(\\sigma\\), and a control list for controlling max iteration number and convergence tolerance. The output of this function is the EM estimate of all the parameters. Here is a function to generate data from the mixture regression model. regmix_sim &lt;- function(n, pi, beta, sigma) { K &lt;- ncol(beta) p &lt;- NROW(beta) xmat &lt;- matrix(rnorm(n * p), n, p) # normal covaraites error &lt;- matrix(rnorm(n * K, sd = sigma), n, K) ymat &lt;- xmat %*% beta + error # n by K matrix ind &lt;- t(rmultinom(n, size = 1, prob = pi)) y &lt;- rowSums(ymat * ind) data.frame(y, xmat) } Generate data with the following and estimate the parameters. n &lt;- 400 pi &lt;- c(.3, .4, .3) bet &lt;- matrix(c( 1, 1, 1, -1, -1, -1), 2, 3) sig &lt;- 1 set.seed(1205) dat &lt;- regmix_sim(n, pi, bet, sig) ## regmix_em(y = dat[,1], xmat = dat[,-1], ## pi.init = pi / pi / length(pi), ## beta.init = matrix(rnorm(6), 2, 3), ## sigma.init = sig / sig, ## control = list(maxit = 500, tol = 1e-5)) 4.8.2 Acceleration of EM algorithm Use the SQUAREM package to accelerate the EM algorithm of the finite mixture regression. See Ravi Varadhan’s article for his example. Write a function regmix_em1step() to implement the one-step EM iteration. Wrap your implementation of the EM algorithm to a function that uses regmix_em1step(). Call SQUAREM::squarem() with appropriate inputs to find the MLE. Compare the speed of the two versions with package microbenchmark. 4.8.3 A Poisson-HMM for earthquake data Consider a \\(m\\)-state HMM where the observed data follows a Poisson distribution with mean \\(\\lambda_i\\) for state \\(i\\), \\(i = 1, \\ldots, m\\), respectively. This model has three sets of parameters initial distribution \\(\\delta\\), transition probability matrix \\(\\Gamma\\), and Poisson means \\(\\lambda = (\\lambda_1, \\ldots, \\lambda_m)\\). Suppose the observed data is a vector \\(x\\). Write a function poisson.hmm.em() that implements the EM algorithm for this model with these argument: x: the observed data; m: the number of states; lambda: initial value of \\(\\lambda\\); Gamma: initial value of \\(\\Gamma\\); delta: initial value of \\(\\delta\\); control: a named list similar to that specifies the tolerance, maximum number of iteration, and whether or not trace the iteration. Apply the function to model the frequency of major earthquakes (magnitude 7 or above) in the world from 1900 to 2015 with a 2-state HMM and a 3-state HMM. ## frequency of major earthquake in the world from 1900 to 2015 ## raw data accessed at http://earthquake.usgs.gov/earthquakes/search/ qk7freq &lt;- c(3, 2, 4, 1, 2, 5, 8, 3, 2, 5, 5, 7, 3, 4, 6, 4, 8, 5, 12, 8, 7, 9, 7, 12, 9, 12, 13, 11, 16, 15, 9, 19, 9, 8, 12, 14, 11, 9, 21, 14, 7, 13, 11, 18, 13, 5, 10, 13, 11, 9, 13, 11, 7, 9, 6, 10, 8, 21, 8, 8, 13, 12, 10, 17, 12, 18, 9, 11, 22, 14, 17, 20, 16, 9, 11, 13, 14, 10, 12, 8, 6, 10, 7, 14, 14, 15, 11, 13, 11, 9, 18, 17, 13, 12, 13, 20, 15, 16, 12, 18, 15, 16, 13, 15, 16, 11, 11, 18, 12, 17, 24, 20, 16, 19, 12, 19) ## forward/backward probability for Poisson-HMM from ## Zucchini and MacDonald (2009): ## Hidden Markov Models for Time Series: An Introduction with R. pois.HMM.lalphabeta &lt;- function(x, m, lambda, gamma, delta = NULL) { if (is.null(delta)) delta &lt;- solve(t(diag(m) - gamma + 1), rep(1, m)) n &lt;- length(x) lalpha &lt;- lbeta &lt;- matrix(NA, m, n) allprobs &lt;- outer(x, lambda, dpois) foo &lt;- delta * allprobs[1, ] sumfoo &lt;- sum(foo) lscale &lt;- log(sumfoo) foo &lt;- foo/sumfoo lalpha[, 1] &lt;- log(foo) + lscale for (i in 2:n) { foo &lt;- foo %*% gamma * allprobs[i, ] sumfoo &lt;- sum(foo) lscale &lt;- lscale + log(sumfoo) foo &lt;- foo/sumfoo lalpha[, i] &lt;- log(foo) + lscale } lbeta[, n] &lt;- rep(0, m) foo &lt;- rep(1/m, m) lscale &lt;- log(m) for (i in (n - 1):1) { foo &lt;- gamma %*% (allprobs[i + 1, ] * foo) lbeta[, i] &lt;- log(foo) + lscale sumfoo &lt;- sum(foo) foo &lt;- foo/sumfoo lscale &lt;- lscale + log(sumfoo) } list(la = lalpha, lb = lbeta) } References "],["random-number-generation.html", "Chapter 5 Random Number Generation 5.1 Univariate Random Number Generation 5.2 Stochastic Processes 5.3 Exercises", " Chapter 5 Random Number Generation (Wiki) A pseudorandom number generator (PRNG), also known as a deterministic random bit generator (DRBG), is an algorithm for generating a sequence of numbers whose properties approximate the properties of sequences of random numbers. The PRNG-generated sequence is not truly random, because it is completely determined by a relatively small set of initial values, called the PRNG’s seed (which may include truly random values). 5.1 Univariate Random Number Generation Random number from standard uniform distribution \\(U(0, 1)\\) is crucial. To illustrate that pseudorandom numbers are deterministic, consider a multiplicative random number generator \\[ I_{n+1} = 7^5 I_n\\mathrm{mod} (2^{31} - 1). \\] runif.my &lt;- function(n, seed) { ret &lt;- double(n) last &lt;- seed p &lt;- 2^31 - 1 for (i in 1:n) { last &lt;- (7^5 * last) %% p ret[i] &lt;- last / p } ret } u &lt;- runif.my(1000, 2) The randomness can be viewed from a histogram and can be tested, for example, with the KS test. hist(u) ks.test(u, &quot;punif&quot;) ## ## One-sample Kolmogorov-Smirnov test ## ## data: u ## D = 0.020604, p-value = 0.7896 ## alternative hypothesis: two-sided In R, check ?RNG. We assume that generation from \\(U(0,1)\\) has been solved for all practical purposes and focus on turning uniform variables to variables with other desired distributions. 5.1.1 Inverse CDF For a non-decreasing function \\(F\\) on \\(\\mathbb{R}\\), the generalized inverse of \\(F\\), \\(F^-\\), is the function \\[ F^-(u) = \\inf\\{x: F(x) \\ge u\\}. \\] If \\(U\\) is \\(U(0, 1)\\), then \\(F^-(U)\\) has distribution \\(F\\). For continuous variables, \\(F^-\\) is simply \\(F^{-1}\\), the quantile function or inverse probability integral transformation. This works for both continuous and non-continuous variables. Average numbers of searches for Poisson variate generation with mean \\(\\lambda\\) (Ross’s Simulation book, p.51). Given a \\(U\\), the inversion algorithm successively checks if the Poisson variate is 0, 1, 2, and so on, which on average takes \\(1 + \\lambda\\) searches. It can be greatly improved by first checking on the integers that are closest to \\(\\lambda\\). Let \\(I\\) be the integer part of \\(\\lambda\\). To generate a Poisson variate \\(X\\), check whether or not \\(X \\le I\\) by seeing whether or not \\(U \\le F(I)\\). Then search downward starting from \\(I\\) if \\(X \\le I\\) and upward from \\(I + 1\\) otherwise. On average the number of searches needed by this algorithm is roughly 1 more than the mean absolute difference between \\(X\\) and \\(\\lambda\\). By \\(N(\\lambda, \\lambda)\\) approximation, this is approximately \\[ 1 + E |X - \\lambda| = 1 + 0.798 \\sqrt{\\lambda}. \\] The {rpois()} function in R uses an efficient algorithm that generates variables for \\(\\lambda \\ge 10\\) by truncating suitable normal deviates and applying a correction with low probability (Ahrens and Dieter 1982). 5.1.2 Rejection Method Idea: To sample from \\(f\\), we sample from \\(g\\) and accept the sample with certain rate to make sure the resulting variable follows \\(f\\). Setup: 1) densities \\(f\\) and \\(g\\) has the same support. 2) \\(f(x) \\le M g(x)\\) for some \\(M &gt; 0\\). The rejection algorithm: Generate \\(Y\\) from \\(g\\). Generate \\(U\\) from standard uniform. If \\(U \\le f(Y) / [M g(Y)]\\), output \\(X = Y\\); otherwise, return to step 1. Validity proof: For \\(x\\) in \\(\\mathcal{X}\\), the support of \\(f\\) and \\(g\\), show that \\(\\Pr(X \\le x) = \\Pr(Y \\le x \\mid \\mbox{Accept}) = \\int_{-\\infty}^x f(y) \\mathrm{d}y\\). Fundamental theorem of simulation: Simulating from \\(X \\sim f(x)\\) is equivalent to simulating from \\((X, U) ~ \\mathcal{U}\\{\\{x, u\\}: 0 &lt; u &lt; f(x)\\}\\). (Hint: the marginal density of \\(X\\) is \\(f(x)\\).) Efficiency: The probability of acceptance is exactly \\(1 / M\\). The expected number of trials until a variable is accepted is \\(M\\). Among choices of \\(g\\), \\(g_i\\)’s, the optimal sampler minimizes \\(M\\). rNormTail &lt;- function(n, c) { lambda &lt;- (c + sqrt(c * c + 4)) / 2 alpha &lt;- exp(0.5 * lambda * lambda - lambda * c) / sqrt(2 * pi) / lambda / (1 - pnorm(c)) x &lt;- rep(NA, n) for (i in 1:n) { while (TRUE) { cand &lt;- rexp(1, lambda) ratio &lt;- dnorm(cand + c) / (1 - pnorm(c)) / dexp(cand, lambda) / alpha u &lt;- runif(1) if (u &lt; ratio) break } x[i] &lt;- cand } x + c } rNormTail.f &lt;- function(n, c, batSize = n) { lambda &lt;- (c + sqrt(c * c + 4)) / 2 alpha &lt;- exp(0.5 * lambda * lambda - lambda * c) / sqrt(2 * pi) / lambda / (1 - pnorm(c)) x &lt;- rep(NA, n) ndone &lt;- 0 while (TRUE) { cand &lt;- rexp(batSize, lambda) ratio &lt;- dnorm(cand + c) / (1 - pnorm(c)) / dexp(cand, lambda) / alpha u &lt;- runif(batSize) accept &lt;- u &lt; ratio naccpt &lt;- sum(accept) ntodo &lt;- n - ndone ngood &lt;- min(ntodo, naccpt) sample &lt;- cand[accept][1:ngood] x[ndone + 1:ngood] &lt;- sample ndone &lt;- ndone + ngood if (ndone == n) break } x + c } cc &lt;- 7 n &lt;- 1000 x1 &lt;- qnorm(runif(n, pnorm(cc), 1)) x2 &lt;- rNormTail(n, cc) x3 &lt;- rNormTail.f(n, cc) hist(x1, freq=FALSE) curve(dnorm(x) / (1 - pnorm(cc)), 7, max(x1), add=TRUE) library(microbenchmark) microbenchmark(x1 &lt;- qnorm(runif(n, pnorm(cc), 1)), x2 &lt;- rNormTail(n, cc), x3 &lt;- rNormTail.f(n, cc, n), x4 &lt;- rNormTail.f(n, cc, n / 2)) ## Unit: microseconds ## expr min lq mean median ## x1 &lt;- qnorm(runif(n, pnorm(cc), 1)) 91.211 92.8255 97.03013 96.368 ## x2 &lt;- rNormTail(n, cc) 6240.373 6396.4580 7144.71968 6479.923 ## x3 &lt;- rNormTail.f(n, cc, n) 363.100 369.5605 385.57957 379.774 ## x4 &lt;- rNormTail.f(n, cc, n/2) 293.763 302.6890 318.16556 315.494 ## uq max neval ## 100.0890 109.158 100 ## 6545.1260 14682.738 100 ## 391.4545 496.655 100 ## 325.3295 390.709 100 5.1.3 Sampling Importance Resampling ##&#39; Sampling importance resampling ##&#39; ##&#39; @param n desired sample size ##&#39; @param density target density ##&#39; @param envolope density of the sampler ##&#39; @param sampler random number generation of the sampler ##&#39; @param m sample size to draw from the sampler ##&#39; @return vector of random sample from the target density sir &lt;- function(n, density, envolope, sampler, m = 20 * n) { y &lt;- sampler(m) weight &lt;- density(y) / envolope(y) weight &lt;- weight / sum(weight) ## resample sample(y, size = n, replace = TRUE, prob = weight) } n &lt;- 5000 ## sample from normal using cauchy as sampler x &lt;- sir(n, dnorm, dcauchy, rcauchy) hist(x, prob = TRUE) curve(dnorm(x), add = TRUE, col=&quot;darkblue&quot;) length(unique(x)) # not equal to n ## [1] 4834 ## sample from cauchy using normal as sampler: bad! y &lt;- sir(n, dcauchy, dnorm, rnorm) hist(y, xlim = c(-7, 7), prob = TRUE) curve(dcauchy(x), add = TRUE, col = &quot;darkblue&quot;) 5.2 Stochastic Processes A stochastic or random process is a collection of random variables indexed by certain set. The indexing set is often a subset of time or space. When the indexing set is multidimensional, the stochastic process is also called a random field. 5.2.1 Gaussian Markov Process Simulation of Brownian motion and Brianian bridge on a grid time grid. ## Brownian motion rBM &lt;- function(tgrid, x0 = 0) { dt &lt;- diff(tgrid) z &lt;- rnorm(length(dt), sd = sqrt(dt)) c(x0, cumsum(z) + x0) } ## Brownian bridge rBB &lt;- function(tgrid, x, y) { n &lt;- length(tgrid) w &lt;- double(n) a &lt;- tgrid[1]; w[1] &lt;- x b &lt;- tgrid[n]; w[n] &lt;- y for (i in 2:(n-1)) { t &lt;- tgrid[i] mu &lt;- ((b - t) * x + (t - a) * y) / (b - a) sigma &lt;- sqrt((t - a) * (b - t) / (b - a)) w[i] &lt;- x &lt;- rnorm(1, mu, sigma) a &lt;- tgrid[i] } w } The square root diffusion process has a closed-form transition distribution, which is a scaled non-central chi-squared. rcir &lt;- function(n, r0, alpha, b, sigma, dt) { df &lt;- 4 * alpha * b / sigma / sigma ee &lt;- exp(- alpha * dt) cc &lt;- sigma^2 * (1 - ee) / 4 / alpha lambda &lt;- ee * r0 / cc rchisq(n, df = df, ncp = lambda) * cc } The transition density would otherwise be approximated by the Euler scheme with a fine time grid. rcir_euler &lt;- function(n, r0, alpha, b, sigma, dt, ng = 10) { ddt &lt;- dt / ng sapply(1:n, function(idx) { for (i in seq(1:ng)) { rt &lt;- r0 + alpha * (b - r0) * ddt + sigma * sqrt(r0 * ddt) * rnorm(1) rt &lt;- max(0, rt) r0 &lt;- rt } rt }) } Here is an illustration. r0 &lt;- .05 alpha &lt;- .2 b &lt;- .05 sigma &lt;- 1 dt &lt;- .1 n &lt;- 1000 x1 &lt;- rcir (n, r0, alpha, b, sigma, dt) x2 &lt;- rcir_euler(n, r0, alpha, b, sigma, dt) qqplot(x1, x2) abline(0, 1) 5.2.2 Counting Process A counting process is a stochastic process \\(\\{N(t); t ≥ 0\\}\\) with values that are non-negative, integer, and non-decreasing. It is often used to model the occurrence of certain event. 5.2.2.1 Homogeneous Poission Process A counting process is a homogeneous Poission process if it satisfies three conditions: \\(N(0) = 0\\); the occurrences of events in disjoint time intervals are independent; the number of events in any interval of length \\(t\\) is a Poisson random variable with mean \\(\\lambda t\\). It can be shown that, conditional on the total number of events in an interval \\((0, \\tau]\\), the event times are distributed as order statistics from a random sample with uniform distribution over \\((0, \\tau]\\). Simulation of a homogeneous Poisson process with indensity \\(\\lambda\\) over \\((0, \\tau]\\) can then be done in two steps. Generate \\(N\\) from a Poisson distribution with mean \\(\\lambda \\tau\\). Generate \\(N\\) variables from the uniform distribution over \\((0, \\tau]\\) and get their order statistics. The resulting \\(N\\) variables are the simulated event times. It can be shown that the inter-arrival distribution of a homogeneous Poisson process with intensity \\(\\lambda\\) are independent and identically distributed exponential variables with rate \\(\\lambda\\). This result gives an alternative simulation approach. 5.2.3 Inhomogeneous Poisson Process An inhomogeneous Poisson process is a characterized by an intensity function \\(\\lambda(t)\\) such that N(0) = 0; the occurrences of events in disjoint time intervals are indepdent; the number of events in an interval \\((0, \\tau]\\) is a Poissoin random variable with mean \\(\\Lambda(\\tau) = \\int_0^\\tau \\lambda(t) \\mathrm{d}{t}\\). The inversion method generates inter-arrival event times (Cinlar 1975, 96). Consider an nonhomomegeneous Poisson process with mean function \\(\\Lambda(t)\\), \\(t &gt; 0\\), which is continuous and nondecreasing. If \\(\\Lambda(T_1), \\Lambda(T_2), \\ldots\\) are event times from a homogeneous Poisson process with rate one, then \\(T_1, T_2, \\ldots\\) are event times from a nonhomogeneous Poisson process with mean function \\(\\Lambda(t)\\). The algorithm works as follows. Generate \\(S_1, S_2, \\ldots\\) from a homogeneous Poisson process with rate one. Let \\(T_i = \\Lambda^{-1}(S_i)\\), \\(i = 1, 2, \\ldots\\). The order statistics method : Let \\(T_1, T_2, \\ldots\\) be random variables representing the event times of a nonhomogeneous Poisson process with continuous mean function \\(\\Lambda(t)\\), \\(t &gt; 0\\). Let \\(N_t\\) be the cumulative number of events by time \\(t\\). Conditional on \\(N_{\\tau} = n\\) over the interval \\((0, \\tau]\\), the event times \\(T_1, T_2, \\ldots\\) are distributed as order statistics from a random sample with distribution function \\(F(t) = \\Lambda(t) / \\Lambda(\\tau)\\), \\(t \\in (0, \\tau]\\). The thinning method (process analog of the acceptance-rejection method) (Lewis and Shedler 1979): Let \\(\\lambda_{\\max} = \\max_{t \\in (0, \\tau]} \\lambda(t)\\). Suppose that \\(S_1, S_2, \\ldots\\) are event times from a homogeneous Poisson process with rate function \\(\\lambda_{\\max}\\). If the \\(i\\)th event time \\(S_i\\) is independently accepted with probability \\(\\lambda(t) / \\lambda_{\\max}\\), the the remaining event times form a realization from a nonhomogeneous Poisson process with rate function \\(\\lambda(t)\\) in \\((0, \\tau]\\). ## simulation of a nonhomegeneous Poisson process ## with the thinning method rnhpp &lt;- function(intensity, intmax, tmax) { n &lt;- rpois(1, intmax) tt &lt;- runif(n, 0, tmax) u &lt;- runif(n) accept &lt;- u &lt; intensity(tt) / intmax sort(tt[accept]) } intfun &lt;- function(x) sin(2 * pi * x) + 1 ff &lt;- rnhpp(intfun, 2, 1) hist(unlist(replicate(10000, rnhpp(intfun, 2, 1)))) Discussion: what are the pros and cons of these methods? 5.2.4 Jump-Diffusion Process Simulation from a jump-diffusion process on a given time grid in a simple setting with a homogeneous Poisson process for the jump events and a lognormal jump sizes. ## jump rate: constant lambda ## jump size: log normal distribution with meanlog and sdlog rjd &lt;- function(tgrid, x0, mu, sigma, lambda, meanlog, sdlog) { dt &lt;- diff(tgrid) n &lt;- length(dt) ddiff &lt;- (mu - 0.5 * sigma * sigma) * dt + sigma * sqrt(dt) * rnorm(n) njump &lt;- rpois(n, dt * lambda) jsize &lt;- ifelse(njump == 0, 0, rnorm(n, meanlog * njump, sdlog * sqrt(njump))) dx &lt;- ddiff + jsize c(x0, x0 + cumsum(dx)) } meanlog &lt;- 0; sdlog &lt;- 0.02 lambda &lt;- 2; mu &lt;- .01; sigma &lt;- sqrt(.02) x0 &lt;- .05 tgrid &lt;- seq(0, 10, by = .01) plot(ts(xx &lt;- rjd(tgrid, x0, mu, sigma, lambda, meanlog, sdlog))) 5.3 Exercises 5.3.1 Rejection sampling Let \\(f\\) and \\(g\\) be two probability densities on \\((0,\\infty)\\), such that \\[\\begin{align*} f(x) \\propto \\sqrt{4+x}\\,x^{\\theta-1} e^{-x}, \\quad g(x) \\propto (2 x^{\\theta-1} + x^{\\theta-1/2}) e^{-x}, \\quad x&gt;0. \\end{align*}\\] Find the value of the normalizing constant for \\(g\\), i.e., the constant \\(C\\) such that \\[\\begin{align*} C\\int_0^\\infty (2 x^{\\theta-1} + x^{\\theta-1/2}) e^{-x} \\mathrm{d}x=1. \\end{align*}\\] Show that \\(g\\) is a mixture of Gamma distributions. Identify the component distributions and their weights in the mixture. Design a procedure (pseudo-code) to sample from \\(g\\); implement it in an R function; draw a sample of size \\(n = 10,000\\) using your function for at least one \\(\\theta\\) value; plot the kernel density estimation of \\(g\\) from your sample and the true density in one figure. Design a procedure (pseudo-code) to use rejection sampling to sample from \\(f\\) using \\(g\\) as the instrumental distribution. Overlay the estimated kernel density of a random sample generated by your procedure and \\(f\\). 5.3.2 Mixture Proposal Let \\(f\\) be a probability density on \\((0,1)\\) such that \\[\\begin{align*} f(x) \\propto \\frac{x^{\\theta-1}}{1+x^2} + \\sqrt{2+x^2} (1-x)^{\\beta-1}, \\quad 0&lt;x&lt;1. \\end{align*}\\] Design a procedure (pseudo-code) to sample from \\(f\\) using a mixture of Beta distributions as the instrumental density. That is, the instrumental density should have the form \\[\\begin{align*} \\sum_{k=1}^m p_k g_k(x), \\end{align*}\\] where \\(p_k\\) are weights and \\(g_k\\) are densities of Beta distributions. Specify your choice of the mixture. Implement your algorithm in an R function. Graph the estimated density of a random sample of \\(n = 10,000\\) generated by your procedure and \\(f\\) for at least one \\((\\theta, \\beta)\\). As shown in class, \\(f(x)\\) can also be sampled using rejection sampling, by dealing with the two components \\[\\begin{align*} \\frac{x^{\\theta-1}}{1+x^2}, \\quad \\sqrt{2+x^2} (1-x)^{\\beta-1} \\end{align*}\\] separately using individual Beta distributions. Design a procedure (pseudo-code) to do this; implement it with an R function; overlay the estimated density of a random sample of size \\(n = 10,000\\) generated by your procedure and \\(f\\). 5.3.3 Orstein–Uhlenbeck Process Consider the Ornstein-Uhlenbeck process \\[\\begin{align*} \\mathrm{d}r(t) = \\alpha(b - r(t))\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W(t), \\end{align*}\\] where \\(\\alpha &gt; 0\\), \\(\\sigma &gt; 0\\), and \\(b\\) are constants. Show that for \\(t&gt;0\\) and \\(\\Delta&gt;0\\), \\[\\begin{align*} r(t+\\Delta) = e^{-\\alpha\\Delta} r(t) + b(1-e^{-\\alpha\\Delta}) + \\frac{\\sigma}{\\sqrt{2\\alpha}} \\sqrt{1-e^{-2\\alpha\\Delta}} Z, \\end{align*}\\] where \\(Z\\sim N(0,1)\\). Use the transition distribution from the last part to implement a random walk construction for the process on time interval \\([0,T]\\). Your code should take \\(\\alpha\\), \\(\\sigma\\), \\(b\\), the initial value \\(r(0)\\), \\(T\\), and the time step \\(\\Delta\\) of the random walk as input arguments. For \\(r(0)=1\\), \\(T=500\\), and \\(\\Delta = 1/500\\), plot a sample path for each combination of the following values, \\[\\begin{align*} \\alpha \\in \\{0.1, 1, 5\\},\\ \\sigma \\in \\{0.1, 0.2, 0.5\\},\\ b\\in\\{-5, 5\\}. \\end{align*}\\] Comment on how the behavior of \\(r(t)\\) depends on \\(\\alpha\\) and \\(\\sigma\\). Use the Euler–Maruyama method (or the Euler method; see Wiki) to approximate a simulation from the process. Specifically, partition the time interval into a grid with subintervals of equal length \\(\\delta &gt; 0\\) for a small \\(\\delta\\); approximate \\(r(t + \\delta)\\) by a normal random variable with mean \\(r(t) + \\alpha(b - r(t)) \\delta\\) and standard deviation \\(\\sigma \\delta\\). Write a function to implement this approximation with \\(\\delta\\) as one of the arguments. For \\(\\delta \\in \\{1, 0.5, 0.1, 0.01\\}\\), generate a sample of size 1000 for \\(r(1)\\). Plot the kernel densities against the true density. 5.3.4 Poisson Process Let \\(\\lambda(t) = \\sqrt{t} + e^{-t} \\sin(2 \\pi t)\\) be the intensity function of Poisson process over \\(t \\in [0, 5]\\). Let \\(N(t)\\) be the number of events by time \\(t\\). What is the distribution of \\(N(5)\\) and its parameter(s)? Use Mathematica or Maple for integration if needed. Write a function to simulate from this Poisson process. Generate events from this Poisson process 1,000 times. Pool all the event points together as a sample and plot their kernel density. Overlay \\(\\lambda(t) / \\int_0^5 \\lambda(s) \\mathrm{d}s\\) with the kernel density. References "],["markov-chain-monte-carlo.html", "Chapter 6 Markov Chain Monte Carlo 6.1 Eample: Normal mixture 6.2 General-Purpose Gibbs Sampling with the ARMS 6.3 Exercises", " Chapter 6 Markov Chain Monte Carlo 6.1 Eample: Normal mixture Generate some data with mixing rate \\(\\delta\\). delta &lt;- 0.7 # true value to be estimated based on the data n &lt;- 100 set.seed(123) u &lt;- rbinom(n, prob = delta, size = 1) x &lt;- rnorm(n, ifelse(u == 1, 7, 10), 0.5) Assuming that the normal distribution parameters \\(\\mu_1\\), \\(\\sigma_1^2\\), \\(\\mu_2\\), and \\(\\sigma_2^2\\) are known. The only unknown parameter is \\(\\delta\\). The likelihood function of \\(\\delta\\) is mylike &lt;- function(delta, x) { prod(delta * dnorm(x, 7, 0.5) + (1 - delta) * dnorm(x, 10, 0.5)) } We impose an uninformative prior on \\(\\delta\\) and use a simple random walk proposal to construct the Metropolis–Hasting algorithm. ## simple random walk chain myRange &lt;- function(v, width) { min(1, v + width) - max(0, v - width) } mymcmc &lt;- function(niter, init, x, width) { v &lt;- double(niter) for (i in 1:niter) { cand &lt;- runif(1, max(0, init - width), min(1, init + width)) ratio &lt;- mylike(cand, x) / myRange(cand, width) / mylike(init, x) * myRange(init, width) if (runif(1) &lt; min(ratio, 1)) { v[i] &lt;- init &lt;- cand } else v[i] &lt;- init } v } With initial value \\(\\delta_0 = .2\\) and stepsize \\(.1\\) in the random walk proposal, we run the 2500 iterations and throw away the first 500 iterations. niter &lt;- 2500 plot(ts(z &lt;- mymcmc(niter, .2, x, .1)[-(1:500)])) hist(z) 6.2 General-Purpose Gibbs Sampling with the ARMS Consider an example of posterior inference. Suppose that \\((Y_i, X_i)\\), \\(i = 1, \\ldots, n\\), are observed, where \\[ Y_i \\mid X_i \\sim \\mbox{Poisson}(\\exp(a + b X_i)). \\] This is a Poisson regression model. Assume independent prior distributions on \\(a\\) and \\(b\\) with \\(N(0, \\sigma^2)\\) and \\(N(0, \\tau^2)\\). The posterior density of \\((a, b)\\) is \\[ q(a, b \\mid \\mbox{data}) \\propto \\exp\\left(a \\sum_i^n Y_i + b \\sum_i^n X_i Y_i - e^a \\sum_i^n e^{X_i b} - \\frac{a^2}{2\\sigma^2} - \\frac{b^2}{2\\tau^2}\\right). \\] The full conditional distributions of \\(a\\) and \\(b\\) can be shown to be log-concave, which allows adaptive rejection alogorithm (Robert and Casella 2004). One could also just use the general ARMS as a lazy man’s approach. Let us first generate some data. n &lt;- 100 a &lt;- 0.0; b &lt;- 0.5 x &lt;- rnorm(n) y &lt;- rpois(n, exp(a + b * x)) mydata &lt;- data.frame(y = y, x = x) The posterior density up to an unknown normalizing constant can be easily computed. logpost &lt;- function(theta, data, sigma2, tau2) { a &lt;- theta[1]; b &lt;- theta[2] x &lt;- data$x; y &lt;- data$y return(a * sum(y) + b * sum(x * y) - exp(a) * sum(exp(b * x)) - a^2 / 2 / sigma2 - b^2 / 2 / tau2) } An MCMC based the Gibbs sampler uses the ARMS algorithm from R package HI. mymcmc &lt;- function(niter, thetaInit, data, sigma2, tau2, nburn= 100) { p &lt;- length(thetaInit) thetaCurrent &lt;- thetaInit ## define a function for full conditional sampling logFC &lt;- function(th, idx) { theta &lt;- thetaCurrent theta[idx] &lt;- th logpost(theta, data, sigma2, tau2) } out &lt;- matrix(thetaInit, niter, p, byrow = TRUE) ## Gibbs sampling for (i in 2:niter) { for (j in 1:p) { ## general-purpose arms algorithm out[i, j] &lt;- thetaCurrent[j] &lt;- HI::arms(thetaCurrent[j], logFC, function(x, idx) ((x &gt; -10) * (x &lt; 10)), 1, idx = j) } } out[-(1:nburn), ] } Now give it a try with \\(\\sigma^2 = 100\\) and \\(\\tau^2 = 100\\). niter &lt;- 600; nburn &lt;- 100 thetaInit &lt;- c(2, 2) sigma2 &lt;- tau2 &lt;- 100 sim &lt;- mymcmc(niter, thetaInit, mydata, sigma2, tau2) plot(ts(sim[,1])) plot(ts(sim[,2])) 6.3 Exercises 6.3.1 Normal mixture revisited Consider again the normal mixture example, except that the parameters of the normal distributions are considered unknown. Suppose that prior for \\(\\mu_1\\) and \\(\\mu_2\\) are \\(N(0, 10^2)\\), that the prior for \\(1/\\sigma_1^2\\) and \\(1/\\sigma_2^2\\) are \\(\\Gamma(a, b)\\) with shape \\(a = .5\\) and scale \\(b = 10\\). Further, all the priors are independent. Design an MCMC using the Gibbs sampling approach to estimate all 5 parameters. You may use the arms()function in package HI. Run your chain for sufficiently long and drop the burn-in period. Plot the histogram of the results for all the parameters. References "],["mcinteg.html", "Chapter 7 Monte Carlo Integration 7.1 Introduction 7.2 Option Pricing 7.3 Particle Filtering for State Space Models 7.4 Variance Reduction 7.5 Exercises", " Chapter 7 Monte Carlo Integration 7.1 Introduction Evaluate integral \\[\\begin{equation*} E_f[ h(X)] = \\int_{\\mathcal{X}} h(x) f(x) \\mathrm{d}x. \\end{equation*}\\] If sampling from \\(f\\) can be done, approximate by sample average \\[\\begin{equation*} \\bar h_n = \\frac{1}{n}\\sum_{j=1}^n h(X_j), \\end{equation*}\\] where \\(X_1, \\ldots, X_n\\) are a random sample from \\(f\\). The convergence is enforced by the SLLN. The speed of the convergence can be assessed if \\(E h^2(X) &lt; \\infty\\) with the CLT. f &lt;- function(x) log(abs(x)) * exp(- (x + 1)^2 / 8) integrate(f, -Inf, Inf) ## 0.8919911 with absolute error &lt; 5.5e-06 ## Monte Carlo approximation nrep &lt;- 1000 n &lt;- 10000 ## normal sampler ## i.n &lt;- replicate(nrep, sqrt(8 * pi) * mean(log(abs(rnorm(n, -1, 2))))) i.n &lt;- replicate(nrep, {x &lt;- rnorm(n, -1, 2); mean(f(x) / dnorm(x, -1, 2))}) mean(i.n) ## [1] 0.8904976 sd(i.n) ## [1] 0.05637411 ## cauchy sampler i.c &lt;- replicate(nrep, {x &lt;- rcauchy(n, -1, 2); mean(f(x) / dcauchy(x, -1, 2))}) mean(i.c) ## [1] 0.8929429 sd(i.c) ## [1] 0.06465228 The order of the Monte Carlo error is \\(\\sqrt{\\mathrm{Var}[h(X)] / n}\\). The error of estimating \\(E_f[ h(X)]\\) declines at the rate of \\(n^{-1/2}\\). This is slower than the quadrature method with \\(n\\) quadrature points, which has a rate of \\(O(n^{-k}\\) for \\(k \\ge 2\\) typically. 7.2 Option Pricing blackScholes &lt;- function(strike, time, S0, rfrate, sigma) { crit &lt;- (log(strike / S0) - (rfrate - sigma^2 / 2) * time)/ sigma / sqrt(time) S0 * pnorm(sigma * sqrt(time) - crit) - strike * exp(- rfrate * time) * pnorm(-crit) } S0 &lt;- strike &lt;- time &lt;- 1 rfrate &lt;- 0.06 sigma &lt;- 0.1 ## analytic solution blackScholes(strike, time, S0, rfrate, sigma) ## [1] 0.07459322 ## Monte Carlo approximation myApprox &lt;- function(nsim, strike, time, S0, rfrate, signma) { wt &lt;- rnorm(nsim, sd = sqrt(time) * sigma) value &lt;- mean(pmax(S0 * exp((rfrate - sigma^2 / 2) * time + wt) - strike, 0)) exp(-rfrate * time) * value } mcAppr &lt;- replicate(nrep, myApprox(n, strike, time, S0, rfrate, sigma)) mean(mcAppr) ## [1] 0.0746219 sd(mcAppr) ## [1] 0.000777726 What if the stock price process \\(S(t)\\) is not a geometric Brownian motion? 7.3 Particle Filtering for State Space Models Consider a simple state space model \\[\\begin{eqnarray*} Y_{t} \\mid &amp; X_t, &amp; \\theta &amp; \\sim &amp; N(X_t, &amp; \\sigma^2)\\\\ X_{t} \\mid &amp; X_{t-1},&amp; \\theta &amp; \\sim &amp; N(X_{t-1}, &amp; \\tau^2) \\end{eqnarray*}\\] where \\(X_0 \\sim N(\\mu_0, \\sigma^2_0)\\) and \\(\\theta = (\\sigma^2, \\tau^2)\\). This model is also known as a dynamic linear model. The observed data are \\(Y_1, \\ldots, Y_T\\). We would like to predict the hidden states \\(X_1, \\ldots, X_T\\). For this simple normal model, closed form solutions exist but we use SIS for illustration. First, let’s generate data. dlmSim &lt;- function(n, sigma, tau, x0) { x &lt;- rep(0, n) y &lt;- rep(0, n) x[1] &lt;- rnorm(1, x0, tau) y[1] &lt;- rnorm(1, x[1], sigma) for (t in 2:n) { # loop for clarity; could be vectorized x[t] &lt;- rnorm(1, x[t-1], tau) y[t] &lt;- rnorm(1, x[t], sigma) } data.frame(y = y, x = x) # save x for comparison purpose } Let \\(\\tau^2 = 0.5\\) and \\(\\sigma^2 = 2\\tau^2\\). Generate a series of length \\(n = 50\\). n &lt;- 50 tau &lt;- sqrt(0.5); sigma &lt;- sqrt(2) * tau set.seed(123456) dat &lt;- dlmSim(n, sigma, tau, 0) Now we use apply SIS to make inferences about \\(X_1, \\ldots, X_T\\). dlmSIS &lt;- function(y, sigma, tau, m0, s0, N) { xseq &lt;- matrix(0, n, N) x &lt;- rnorm(N, m0, s0) w &lt;- rep(1/N, N) for (t in 1:n) { x &lt;- rnorm(N, x, tau) w &lt;- w * dnorm(y[t], x, sigma) xseq[t, ] &lt;- x &lt;- sample(x, size = N, replace = TRUE, prob = w) } xseq } We run this SIS with \\(\\mu_0 = 0\\) and \\(\\sigma_0 = 10\\) with \\(N = 1000\\) particles. It is easy to see that the particle sample degenerates. xseq &lt;- dlmSIS(dat$y, sigma, tau, 0, 10, 1000) summary(apply(xseq, 1, function(x) length(unique(x)))) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 8.00 17.25 23.00 34.22 34.75 194.00 plotDlmPf &lt;- function(xseq) { lower &lt;- apply(xseq, 1, quantile, prob = 0.025) upper &lt;- apply(xseq, 1, quantile, prob = 0.975) med &lt;- apply(xseq, 1, median) plot(dat$x, type = &quot;n&quot;, ylim = range(c(dat$x, lower, upper))) points(dat$x) lines(med, lty = 1) lines(lower, lty = 2) lines(upper, lty = 2) } plotDlmPf(xseq) To fight for degeneracy, the sequential importance sampling resampling (SISR), the particles gets updated with uniform weight being the goal. dlmSISR &lt;- function(y, sigma, tau, m0, s0, N) { xseq &lt;- matrix(0, n, N) x &lt;- rnorm(N, m0, s0) for (t in 1:n) { x &lt;- rnorm(N, x, tau) w &lt;- dnorm(y[t], x, sigma) xseq[t, ] &lt;- x &lt;- sample(x, size = N, replace = TRUE, prob = w) } xseq } We rerun the analysis with SISR with the same data and setting. xseq &lt;- dlmSISR(dat$y, sigma, tau, 0, 10, 1000) summary(apply(xseq, 1, function(x) length(unique(x)))) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 173.0 518.2 573.0 530.0 589.0 616.0 plotDlmPf(xseq) Another popular algorithm is the auxiliary particle filter algorithm (APF) of Pitt and Shephard (1999a). The APF uses importance sampling similarly to the bootstrap filter but includes an additional ``look-ahead step&quot;. At each time point t, the APF calculates first-stage weights \\(w_{t|t−1}\\) for particles from time \\(t − 1\\). These weights are calculated using an estimate of the likelihood of the current data given each particle from the previous time point, \\(\\hat p(y_t \\mid x_{t-1})\\). Particles with high first-stage weights correspond to values of the latent state at time \\(t − 1\\) that are likely to generate the observed data at time \\(t\\). The estimate \\(\\hat p(y_t | x_{t-1})\\) can be approximated by choosing an auxiliary variable \\(\\tilde x_t | x_{t-1}\\) and setting \\(\\hat p(y_t | x_{t-1}) = g(y_t|\\tilde x_{t|t−1})\\). Possible methods for choosing \\(\\tilde x_{t | t - 1}\\) include simulating a value from \\(f(x_t|x_{t−1})\\) or taking \\(\\tilde x_{t | t - 1} = \\mathbb{E}(x_t | x_{t−1})\\). dlmAPF &lt;- function(y, sigma, tau, m0, s0, N) { xseq &lt;- matrix(0, n, N) x &lt;- rnorm(N, m0, s0) for (t in 1:n) { w0 &lt;- dnorm(y[t], x, sigma) tilx &lt;- sample(x, size = N, replace = TRUE, prob = w0) x &lt;- rnorm(N, tilx, tau) w &lt;- dnorm(y[t], x, sigma) / dnorm(y[t], tilx, sigma) xseq[t, ] &lt;- x &lt;- sample(x, size = N, replace = TRUE, prob = w) } xseq } xseq &lt;- dlmAPF(dat$y, sigma, tau, 0, 10, 1000) summary(apply(xseq, 1, function(x) length(unique(x)))) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 368.0 561.0 593.0 567.6 598.0 614.0 plotDlmPf(xseq) 7.4 Variance Reduction 7.4.1 Importance Sampling An integral \\(\\int_a^b H(x) \\mathrm{d}x\\) is expressed as \\[ \\mu = \\int_a^b h(x) f(x) \\mathrm{d}x \\] where \\(f(x)\\) is a density with support \\((a, b)\\) and \\(h(x) = H(x) / f(x)\\). An ordinary MC estimator of \\(\\mu\\) is \\[ \\hat\\mu = \\frac{1}{n} \\sum_{i=1}^n h(Z_i) \\] where \\(Z_1, \\ldots, Z_n\\) are a random sample from \\(f\\). An importance sampling estimator is \\[ \\hat\\mu = \\frac{1}{n} \\sum_{i=1}^n \\frac{h(X_i)}{g(X_i)} \\] where \\(X_1, \\ldots, X_n\\) are a random sample from a density \\(g\\) whose support is the same as \\(f\\). This estimator is unbiased with \\(\\mathbb{E}(\\hat\\mu) = \\mu\\), the optimal choice of \\(g\\) should minimize the variance \\(\\hat\\mu\\) or equivalently the second moment of \\(\\hat\\mu\\). From Jensen’s inequality \\[ \\mathbb{E}(\\hat\\mu^2) \\ge \\mathbb{E}^2 (\\hat\\mu) = \\mu^2. \\] When the equality holds, we have \\(\\mathrm{Var}(\\hat\\mu) = 0\\). That is the density \\(g\\) should be chosen such that \\(g(x) \\propto |h(x)| f(x) = |H(x)|\\). The result is slightly irrelevant since \\(\\int_a^b H(x) \\mathrm{d}x\\) is exactly what we need to find out the first place. Nonetheless, it implies that the variance of the weighted estimator is lower if \\(g(z)\\) resembles \\(|h(z)| f(z)\\), in which case, random points are sampled where they are needed most for accuracy. For illustration, Consider MC integration of \\(\\mathbb{E}[ h(X)]\\), where \\(h(x) = x^\\alpha\\) and \\(X\\) is an exponential random variable with mean \\(\\beta\\). The optimal sampler \\(g\\) should be \\(\\Gamma(\\alpha + 1, \\beta)\\). isAppr &lt;- function(n, h, df, dg, rg, ...) { x &lt;- rg(n, ...) mean( h(x) * df(x) / dg(x, ...) ) } alpha &lt;- 3 h &lt;- function(x) x^alpha beta &lt;- 2 df &lt;- function(x) dexp(x, rate = 1 / beta) mySummary &lt;- function(nrep, n, h, df, dg, rg) { ## browser() sim &lt;- replicate(nrep, isAppr(n, h, df, dg, rg)) c(mean = mean(sim), sd = sd(sim)) } sapply(1:6, function(shp) { rg &lt;- function(n) rgamma(n, shape = shp, scale = beta) dg &lt;- function(x) dgamma(x, shape = shp, scale = beta) mySummary(100, 1000, h, df, dg, rg) }) ## [,1] [,2] [,3] [,4] [,5] [,6] ## mean 47.255131 47.857725 47.9267750 48 48.0636864 47.967139 ## sd 6.761963 2.665243 0.8627971 0 0.8602572 1.985869 7.4.1.1 Ruin Probability Consider an insurance company with a reserve \\(x &gt; 0\\). Suppose that it earns premiums at a constant rate \\(p\\) per unit time; that the payments \\(Y_1, Y_2, \\ldots\\) for the claims are independent and identically distributed \\(\\Gamma(\\alpha, \\beta)\\) with mean \\(\\alpha / \\beta\\); that on average it receives \\(\\lambda\\) claims per unit time; and that the premiums flow in at a faster rate than claims are paid out, i.e., \\(\\lambda \\mathbb{E}(Y_i) = \\lambda\\alpha / \\beta &lt; p\\). Let \\(\\xi_i\\) be the interarrival times,,\\(i = 1, 2, \\ldots\\), which follows an expoential distribution with rate \\(\\lambda\\). Then \\[ Z_i = Y_i - p \\xi_i \\] is the loss during the period from the the \\((i-1)\\)th claim to the \\(i\\)th claim and \\[ L_n = \\sum_{i=1}^n Z_i \\] is the total loss by the time of the \\(n\\)th claim. Ruin occurs if and only if \\(L_n &gt; x\\) for some \\(n\\). Let \\(N\\) be the first time \\(L_n\\) passes \\(x\\). Then the ruin probability is \\(\\Pr(N &lt; \\infty)\\). Since \\(\\mathbb{E}Z_i = \\mathbb{E}Y_i - p / \\lambda &lt; 0\\), by the law of large number \\(L_n \\to -\\infty\\) as \\(n \\to \\infty\\). Since \\(x &gt; 0\\), we have \\(\\Pr(N &lt; \\infty) &lt; 1\\), or equivalently, \\(\\Pr(N = \\infty) &gt; 0\\). A naive way to approximate the ruin probabilty is to simulate the the path of \\(L_n\\) many times and count how often \\(L_n\\) passes \\(x\\). Nonetheless, because \\(\\Pr(N = \\infty) &gt; 0\\), how do we get out of the path that has \\(N = \\infty\\)? If we always stop when \\(N &gt; M\\) for a very large number \\(M\\), then we would introduce bias into the estimation. An importance sampler boosts the probability of ruin and guarantees to stop at a finite number of claims. Suppose the density of \\(Z_i\\)’s is \\(f\\). Instead of sampling \\(Z_i\\)’s from \\(f\\), we sampling \\(X_i\\)’s from some density \\(g\\) such that \\(\\mathbb{E}X_i &gt; 0\\) and \\(g(x) &gt; 0\\) wherever \\(f(x) &gt; 0\\). By the law of large number \\(G_n = \\sum_{i=1}^n X_i \\to \\infty\\) with probability one. Therefore, unlike \\(L_n\\), \\(G_n\\) is guaranteed to pass \\(x\\) at a finite \\(n\\). Let \\(\\tau\\) be the first time \\(G_n\\) passes \\(x\\). Then \\[ \\Pr(N &lt; \\infty) = \\mathbb{E}[1 \\{N &lt; \\infty\\}] = \\mathbb{E}\\left[\\prod_{i=1}^\\tau \\frac{f(X_i)}{g(X_i)} 1\\{\\tau &lt; \\infty\\}\\right]. \\] The importance sampling procedure then generate a large number of copies of \\[ V_i = \\prod_{j=1}^\\tau \\frac{f(X_j)}{g(X_j)}, \\qquad i = 1, \\ldots, m, \\] and approximate the ruin probability by \\(\\hat\\mu_g = \\sum_{i=1}^m V_i / m\\). How to select the importance sampler \\(g\\)? Note that in this specific example, the density \\(f\\) of \\(Z_i\\), the difference between two independent gamma variables, involves an integral which cannot be simplified. If we can construct \\(g\\) so that it can cancel the density of \\(f\\), then the evaluation of \\(V_i\\)’s would be made easier. One such approach is exponential tilting where \\[ g(x) = e^{\\theta x - \\psi(\\theta)} f(x), \\] where \\(\\psi(\\theta)\\) is the cumulant generating function of \\(f\\), i.e., \\[ \\psi(\\theta) = \\log \\int e^{\\theta x} f(x) \\mathrm{d}x. \\] In our setting, \\(\\psi(\\theta)\\) is known from the moment generating function of \\(Z_i\\) and \\(p \\xi_i\\). The moment generating function of \\(X_i\\) also reveals that the distribution of \\(X_i\\) is the distribution of the difference between a \\(\\Gamma(\\alpha, \\beta - \\theta)\\) variable and an independent exponential variable with rate \\(\\lambda / p + \\theta\\). This characterization allows simple simulation of \\(X_i\\)$’s. With \\(\\theta\\) selected such that \\(\\mathbb{E}X_i &gt; 0\\), we have \\[ \\Pr(N &lt; \\infty) = \\mathbb{E}\\prod_{i=1}^\\tau e^{\\psi(\\theta) - \\theta X_i} = \\mathbb{E}e^{- \\theta G_{\\tau} + \\psi(\\theta)\\tau}. \\] We can further choose \\(\\theta\\) as the unique positive root \\(\\theta^*\\) to \\(\\psi(\\theta) = 0\\). The existence and uniqueness of \\(\\theta^*\\) is due to the strictly convexity of \\(\\psi(\\theta)\\), \\(\\psi(0) = 0\\), \\(\\psi&#39;(0) = \\mathbb{E}Z_i &lt; 0\\), and \\(\\psi(\\theta) \\to \\infty\\) as \\(\\theta \\to \\infty\\). Then \\[ \\Pr(N &lt; \\infty) = e^{\\theta^* x} \\mathbb{E}e^{ - \\theta^* (G_\\tau - x)}, \\] where \\(G_\\tau - x\\) is the amount of the “overshoot” when \\(G_\\tau\\) first passes \\(x\\). The sampling from the importance sampler is simple from the moment generating function of \\(X_i\\). #&#39; Importance sampler with exponeitial tilting #&#39; $X_i = U_i - V_i$ where #&#39; $U_i$ is gamma(a, b - theta) and $V_i$ is an independent exponential #&#39; with rate lambda / p + theta #&#39; Theta needs to be selected such that E X &gt; 0 rX &lt;- function(n, theta, lambda, a, b, p) { rgamma(n, a, rate = b - theta) - rexp(n, rate = lambda / p + theta) } Now we set some parameter values and plot the \\(psi\\) function. x &lt;- 2 # reserve lambda &lt;- 1; a &lt;- 6; b &lt;- 2; p &lt;- 6 # such that a / b - p / lambda &lt; 0 #&#39; $Z_i = Y_i - p \\xi_i$ such that E[Z_i] &lt; 0 #&#39; where $Y_i$ is Gamma(a, b) with mean a/b, #&#39; $\\xi_i$ is exponential with rate lambda. #&#39; The cumulant generating function of Z as a function of theta psiExpr &lt;- expression(- a * log(1 - t / b) - log(1 + t / lambda * p)) dPsiExpr &lt;- D(psiExpr, &quot;t&quot;) psi &lt;- function(t, lambda, a, b, p) { eval( psiExpr, list(t = t, lambda = lambda, a = a, b = b, p = p)) } dPsi &lt;- function(t, lambda, a, b, p) { eval(dPsiExpr, list(t = t, lambda = lambda, a = a, b = b, p = p)) } curve( psi(x, lambda, a, b, p), 0, 1) curve(dPsi(x, lambda, a, b, p), 0, 1) ## root of psi(theta) = 0 (th0 &lt;- uniroot( psi, c(0.01, 1), lambda = lambda, a = a, b = b, p = p)$root) ## [1] 0.3362335 ## root of dPsi(theta) = 0 (thd0 &lt;- uniroot(dPsi, c(0.01, 1), lambda = lambda, a = a, b = b, p = p)$root) ## [1] 0.1428567 The importance sampling approximation is made more efficient in R by sampling in batches. ## approximation with importance sampler ruinProbAppr &lt;- function(n, lambda, a, b, p, x, theta, batSize = 1000){ do1rep &lt;- function() { lossCum &lt;- 0 tau &lt;- 0 repeat { z &lt;- rX(batSize, theta, lambda, a, b, p) loss &lt;- lossCum + cumsum(z) idx &lt;- which(loss &gt; x) if (length(idx) &gt; 0) break lossCum &lt;- loss[batSize] tau &lt;- tau + batSize } lossCum &lt;- loss[idx[1]] tau &lt;- tau + idx[1] lr &lt;- exp(- theta * lossCum + tau * psi(theta, lambda, a, b, p)) } sim &lt;- replicate(n, do1rep()) mean(sim) } Now we compare the performance at several values of \\(\\theta\\). ## Compare different theta values theta &lt;- c(mean(c(thd0, th0)), (1:2) * th0) nrep &lt;- 50 n &lt;- 200 sim &lt;- sapply(theta, function(th) { srep &lt;- replicate(nrep, ruinProbAppr(n, lambda, a, b, p, x, th)) c(mean = mean(srep), sd = sd(srep)) }) sim ## [,1] [,2] [,3] ## mean 0.312298954 0.310416606 0.30850139 ## sd 0.009255797 0.008025985 0.06320838 7.4.2 Control Variates Suppose that there is another MC estimator \\[ \\hat\\theta = \\frac{1}{n}\\sum_{i=1}^n g(Y_i) \\] whose target \\(\\theta\\) is known. If \\(h(X_i)\\) and \\(g(Y_i)\\) are positively correlated, their dependence can be exploited to construct an improved MC estimator for \\(\\mu\\). The intuition is that if \\(\\hat\\theta\\) is overestimating (underestimating) \\(\\theta\\), it is likely that \\(\\hat\\mu\\) is also overestimating (underestimating) \\(\\mu\\). The known bias in \\(\\hat\\theta\\) can be used to adjust \\(\\hat\\mu\\). The random variable on which \\(\\hat\\theta\\) is based is called a control variate in estimating \\(\\mu\\). Specifically, the control variate MC estimator for \\(\\mu\\) is \\[ \\hat\\mu_{\\mbox{CV}} = \\hat\\mu - b (\\hat\\theta - \\theta) \\] where \\(b\\) is constant designed to minimize the variance of \\(\\hat\\mu_{\\mbox{CV}}\\). Clearly, \\(\\hat\\mu_{\\mbox{CV}}\\) is unbiased and consistent. It reduces to \\(\\hat\\mu\\) when \\(b = 0\\). Given \\(g\\) and the distribution of \\(Y_i\\), \\[ \\mathrm{Var}(\\hat\\mu_{\\mbox{CV}}) = \\mathrm{Var}(\\hat\\mu) + \\mathrm{Var}(\\hat\\theta) - 2 \\mathrm{Cov}(\\hat\\mu, \\hat\\theta). \\] The optimal \\(b\\) that minimizes \\(\\mathrm{Var}(\\hat\\mu_{\\mbox{CV}})\\) is \\[ b_{\\mbox{opt}} = \\frac{\\mathrm{Cov}(\\hat\\mu, \\hat\\theta)}{\\mathrm{Var}(\\hat\\mu)} = \\frac{\\mathrm{Cov}[h(X), g(Y)]}{\\mathrm{Var}[g(Y)]}. \\] The minimized variance is \\[ \\mathrm{Var}(\\hat\\mu_{\\mbox{CV}}) = (1 - \\rho^2) \\mathrm{Var}(\\hat\\mu) \\] where \\(\\rho\\) is the correlation between \\(h(X)\\) and \\(g(Y)\\). In practice, the covariance and variance in the equations are unknown but can be estimated by the their sample version based on the MC sample of \\(X\\) and \\(Y\\). To select a control variate \\(g(Y)\\), we need that \\(E[g(Y)]\\) is known and that the correlation between \\(h(X)\\) and \\(g(Y)\\) is strong. When \\(\\rho = 1\\), we have \\(\\mathrm{Var}(\\hat\\mu_{\\mbox{CV}}) = 0\\). This is not a surprise because in that case \\(h(X)\\) is a linear transformation of \\(g(Y)\\) and \\(\\mu\\) is a linear transformation of \\(\\theta\\). Consider pricing an Asian call option; Example 4.1.2 in Glasserman (2000, p.189). For MC integration, sample paths of BM will be needed. rBM &lt;- function(n, tgrid, sigma) { tt &lt;- c(0, tgrid) dt &lt;- diff(tt) nt &lt;- length(tgrid) dw &lt;- matrix(rnorm(n * nt, sd = sigma * sqrt(dt)), n, nt, byrow = TRUE) t(apply(dw, 1, cumsum)) } If the value the underlying asset at maturity follows a lognormal distribution, then the expected value of a European call option has a closed-form. callValLognorm &lt;- function(S0, K, mu, sigma) { d &lt;- (log(S0 / K) + mu + sigma^2) / sigma S0 * exp(mu + 0.5 * sigma^2) * pnorm(d) - K * pnorm(d - sigma) } We now approximate the present value of an Asian call option. The first estimator is a simple MC estimator, which will be compared with three control variate MC estimator. The three control variates are, respectively, the underlying asset, a standard European call option, and an Asian call option but defined with geometric mean instead of arithmetic mean. optValueAppr &lt;- function(n, r, sigma, S0, K, tgrid) { wt &lt;- rBM(n, tgrid, sigma) ## payoff of call option on arithmetic average nt &lt;- length(tgrid) TT &lt;- tgrid[nt] St &lt;- S0 * exp((r - sigma^2 / 2) * matrix(tgrid, n, nt, byrow = TRUE) + wt) pAri &lt;- pmax(rowMeans(St) - K, 0) vAri &lt;- mean(pAri) ## underlying asset price ST &lt;- St[, nt] vAs &lt;- vAri - cov(ST, pAri) / var(ST) * (mean(ST) - exp(r * TT) * S0) ## value of standard option pStd &lt;- pmax(ST - K, 0) pStdTrue &lt;- callValLognorm(S0, K, (r - 0.5 * sigma^2) * TT, sigma * sqrt(TT)) vStd &lt;- vAri - cov(pStd, pAri) / var(pStd) * (mean(pStd) - pStdTrue) ## payoff of call option on geometric average pGeo &lt;- pmax(exp(rowMeans(log(St))) - K, 0) tbar &lt;- mean(tgrid) sBar2 &lt;- sigma^2 / nt^2 / tbar * sum( (2 * seq(nt) - 1) * rev(tgrid) ) pGeoTrue &lt;- callValLognorm(S0, K, (r - 0.5 * sigma^2) * tbar, sqrt(sBar2 * tbar)) vGeo &lt;- vAri - cov(pGeo, pAri) / var(pGeo) * (mean(pGeo) - pGeoTrue) ## sim &lt;- data.frame(pAri, ST, pStd, pGeo) ## result c(vAri, vAs, vStd, vGeo) * exp(-r * TT) } We run 200 replicates, each with a sample size of 500, and compare the results r &lt;- 0.05; sigma &lt;- 0.3; S0 &lt;- 50; K &lt;- 50 tgrid &lt;- seq(0, .25, length = 14)[-1] sim &lt;- replicate(200, optValueAppr(500, r, sigma, S0, K, tgrid)) apply(sim, 1, mean) ## [1] 1.992368 1.976591 1.977684 1.982716 apply(sim, 1, sd) ## [1] 0.133252648 0.081312123 0.071635329 0.002713132 The standard error using the geometric mean Asian option is strikingly small compared the first version. This is due to the strong correlation between the arithmetic mean Asian option and geometric mean Asian option. 7.4.3 Antithetic Variates Approximate the mean of \\(X^2\\) where \\(X\\) follows the \\(N(0, 1)\\) distribution. myApprox &lt;- function(n) { ## basic MC z &lt;- rnorm(n) mu1 &lt;- mean(z^2) ## antithetic variate 1 ## no reduction in variance za &lt;- -z mu2 &lt;- mean(c(mean(z^2), mean(za^2))) ## antithetic variate 2 y &lt;- qchisq(pnorm(z ), df = 1) ya &lt;- qchisq(pnorm(za), df = 1) mu3 &lt;- mean(c(mean(y), mean(ya))) c(mu1, mu2, mu3) } nrep &lt;- 200; n &lt;- 100 sim &lt;- replicate(nrep, myApprox(n)) apply(sim, 1, mean) ## [1] 1.001890 1.001890 1.001171 apply(sim, 1, sd) ## [1] 0.1262916 0.1262916 0.0669218 7.4.4 Stratified Sampling #&#39; X ~ Lognormal(0, 1) #&#39; Y | X ~ lognormal(9 + 3 log X, 1) #&#39; Find E(Y / X) myraoblack &lt;- function(n) { x &lt;- rlnorm(n, 0, 1) y &lt;- rlnorm(n, 9 + 3 * log(x), 1) ## vanilla version v1 &lt;- mean(y / x) ## Rao-Blackwell version y.x &lt;- exp(9 + 3 * log(x) + 1 / 2) v2 &lt;- mean(y.x / x) c(v1, v2) } sim &lt;- replicate(200, myraoblack(5000)) apply(sim, 1, mean) ## [1] 99429.09 97898.69 apply(sim, 1, sd) ## [1] 35376.27 9270.43 #&#39; @title Generating multivariate normal subject to linear constraint #&#39; @param U a vector of U(0, 1) random variables #&#39; @param Sigma variance matrix #&#39; @param nu vector for the linear projection rmvnormLinCon &lt;- function(U, Sigma, nu) { ## normalize nu such that nu&#39; %*% Sigma %*% nu == 1 nu &lt;- nu / sqrt(c(crossprod(nu, Sigma %*% nu))) n &lt;- length(U); p &lt;- length(nu) ## convert the conditioning U to standard normal scale X &lt;- qnorm(U) ## standard N(0, I_p) Z &lt;- matrix(rnorm(n * p), p, n) ## lower-triang matrix of Cholesky decomposition of Sigma A &lt;- t(chol(Sigma)) ## conditional sampling cmean &lt;- tcrossprod(Sigma %*% nu, X) # a pxn matrix for mean xi &lt;- cmean + (A - Sigma %*% nu %*% crossprod(nu, A)) %*% Z t(xi) # a nxp matrix } optValueSS &lt;- function(n, r, sigma, S0, K, tgrid, nstrata = 10) { nt &lt;- length(tgrid) Sigma &lt;- sigma^2 * outer(tgrid, tgrid, pmin) nu &lt;- rep(1, nt) / nt ## unstratified version U &lt;- runif(n) Wt &lt;- rmvnormLinCon(U, Sigma, nu) St &lt;- S0 * exp((r - sigma^2 / 2) * matrix(tgrid, n, nt, byrow = TRUE) + Wt) pAri &lt;- pmax(rowMeans(St) - K, 0) vAri &lt;- mean(pAri) ## stratified version left &lt;- rep(seq(nstrata) - 1, each = n / nstrata) V &lt;- (left + U) / nstrata # stratified based on U Wt.s &lt;- rmvnormLinCon(V, Sigma, nu) St.s &lt;- S0 * exp((r - sigma^2 / 2) * matrix(tgrid, n, nt, byrow = TRUE) + Wt.s) pAri.s &lt;- pmax(rowMeans(St.s) - K, 0) vAri.s &lt;- mean(pAri.s) c(vAri, vAri.s) } r &lt;- 0.05; sigma &lt;- 0.3; S0 &lt;- 50; K &lt;- 50 tgrid &lt;- seq(0, .25, length = 14)[-1] sim &lt;- replicate(200, optValueSS(500, r, sigma, S0, K, tgrid)) apply(sim, 1, mean) ## [1] 1.988077 2.007031 apply(sim, 1, sd) ## [1] 0.1262231 0.0357946 7.5 Exercises Suppose \\(X\\) has the following probability density function \\[ f(x) = \\frac{1}{5\\sqrt{2\\pi}}x^2 e^{-\\frac{(x-2)^2}{2}}, \\qquad -\\infty &lt;x &lt; \\infty. \\] Consider using the importance sampling method to estimate \\(\\mathbb{E}(X^2)\\). Implement the important sampling method, with \\(g(x)\\) being the standard normal density. Report your estimates using 1000, 10000 and 50000 samples. Also estimate the variances of the estimates. Design a better importance sampling method to estimate \\(\\mathbb{E}(X^2)\\) using a different \\(g(x)\\). Justify your choice of \\(g(x)\\). Implement your method and estimate \\(\\mathbb{E}(X^2)\\) using using 1000, 10000 and 50000 samples. Also estimate the variances of the importance sampling estimates. Compare the two results from the two methods and comment. Consider a geometric Brownian motion \\[\\begin{align*} \\frac{\\mathrm{d}S(t)}{S(t)} = r\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W(t). \\end{align*}\\] Let \\(P_A = e^{-rT}(S_A-K)_+\\), \\(P_E = e^{-rT}[S(T)-K]_+\\), and \\(P_G = e^{-rT}[S_G-K]_+\\), where \\[\\begin{align*} S_A = \\frac{1}{n} \\sum_{i=1}^n S\\left(\\frac{iT}{n}\\right), \\quad S_G = \\left[\\prod_{i=1}^n S\\left(\\frac{iT}{n}\\right)\\right]^{1/n}. \\end{align*}\\] In all the questions below, \\(S(0)=1\\), \\(r=0.05\\), and \\(n=12\\). Write down and implement an algorithm to sample the path of \\(S(t)\\). Set \\(\\sigma=0.5\\) and \\(T=1\\). For each of the values of \\(K \\in \\{1.1, 1.2, 1.3, 1.4, 1.5\\}\\), simulate 5000 sample paths of \\(S(t)\\) to get MC estimates of the correlation coefficients between \\(P_A\\) and \\(S(T)\\), between \\(P_A\\) and \\(P_E\\), and between \\(P_A\\) and \\(P_G\\). How do the correlation coefficients change as \\(K\\) increases? Set \\(T=1\\) and \\(K=1.5\\). For each of the values of \\(\\sigma \\in \\{0.2, 0.3, 0.4, 0.5\\}\\), simulate 5000 sample paths of \\(S(t)\\) to get MC estimates of the correlation coefficients. How do the correlation coefficients change as \\(\\sigma\\) increases? Set \\(\\sigma=0.5\\) and \\(K=1.5\\). For each of the values of \\(T \\in \\{0.4, 0.7, 1, 1.3, 1.6\\}\\), use 5000 sample paths of \\(S(t)\\) to get MC estimates of the correlation coefficients. How do the correlation coefficients change as \\(T\\) increases? Set \\(\\sigma=0.4\\), \\(T=1\\) and \\(K=1.5\\). Use \\(P_G\\) as a control variate to develop a control variate MC estimator for \\(\\mathbb{E}(P_A)\\). Compare its SD with the SD of the MC estimator for \\(\\mathbb{E}(P_A)\\) that has no control variate. "],["boot.html", "Chapter 8 Bootstrap 8.1 Principles of Bootstrap 8.2 Parametric Bootstrap 8.3 Block bootstrap 8.4 Semiparametric bootstrap 8.5 Multiplier bootstrap 8.6 Exercises", " Chapter 8 Bootstrap 8.1 Principles of Bootstrap Example from Efron’s original 1979 paper. median.boot &lt;- function(x, nboot) { tx &lt;- median(x) sx &lt;- sd(x) n &lt;- length(x) do1rep &lt;- function(x) { x.b &lt;- sample(x, length(x), replace = TRUE) abs(median(x.b) - tx) / sx } r.sample &lt;- replicate(nboot, do1rep(x)) c(mean = mean(r.sample) * sqrt(n), sd = sd(r.sample)) } x &lt;- rnorm(13) median.boot(x, 50) ## mean sd ## 0.8155341 0.2507561 sim &lt;- replicate(200, median.boot(rnorm(13), 100)) summary(t(sim)) ## mean sd ## Min. :0.3411 Min. :0.1109 ## 1st Qu.:0.7191 1st Qu.:0.2171 ## Median :0.9299 Median :0.2615 ## Mean :0.9348 Mean :0.2663 ## 3rd Qu.:1.1501 3rd Qu.:0.3134 ## Max. :1.9982 Max. :0.5270 8.2 Parametric Bootstrap A parametric model is specified to the data, and the model parameters are estimated by likelihood methods, moment methods, or other methods. Parametric bootstrap samples are generated from the fitted model, and for each sample the quantity to be bootstrapped is calculated. Parametric bootstrap is often used to approximate the null distribution of a testing statistic which is otherwise unwieldy. The uncertainty of parameter estimation can be accounted for. 8.2.1 Goodness-of-Fit Test Goodness of fit test with the KS statistic. Consider two different null hypotheses: \\[ H_0: \\mbox{ the data follows $N(2, 2^2)$ distribution,} \\] and \\[ H_0: \\mbox{ the data follows a normal distribution.} \\] Note that the first hypothesis is a simple hypothesis while the second one is a composite hypothesis. do1rep &lt;- function(n) { x &lt;- rnorm(n, mean = 2, sd = 2) p1 &lt;- ks.test(x, &quot;pnorm&quot;, mean = 2, sd = 2)$p.value p2 &lt;- ks.test(x, &quot;pnorm&quot;, mean = mean(x), sd = sd(x))$p.value c(p1, p2) } set.seed(2020-12-01) pvals &lt;- replicate(1000, do1rep(100)) ## par(mfrow=c(1, 2), mar=c(2.5, 2.5, 0.1, 0.1), mgp=c(1.5, 0.5, 0)) hist(pvals[1,]) hist(pvals[2,]) ks.test(pvals[1,], &quot;punif&quot;) ## ## One-sample Kolmogorov-Smirnov test ## ## data: pvals[1, ] ## D = 0.043786, p-value = 0.04322 ## alternative hypothesis: two-sided ks.test(pvals[2,], &quot;punif&quot;) ## ## One-sample Kolmogorov-Smirnov test ## ## data: pvals[2, ] ## D = 0.47133, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided Compare the histograms of the p-values obtained from applying ks.test() to \\(N(2, 2^2)\\) and to \\(N(\\hat\\mu, \\hat\\sigma^2)\\) with fitted mean \\(\\hat\\mu\\) and variance \\(\\hat\\sigma^2\\). The first one is what is expected from a \\(U(0, 1)\\) distribution, but the second one is not, which confirms that direct application of ks.test() to fitted distribution is incorrect for the goodness-of-fit of the hypothesized distribution with unknown parameters that need to be estimated. A parametric bootstrap procedure can be employed for such tests. The test statistic remain the same, but its null distribution is approximated from parametric bootstrap. my.ks.normal &lt;- function(x, B = 1000) { ## mle mu &lt;- mean(x) sigma &lt;- sd(x) ## KS stat stat &lt;- ks.test(x, &quot;pnorm&quot;, mu, sigma)$statistic ## parametric bootstrap to approximate the null distribution n &lt;- length(x) stat.b &lt;- double(B) for (i in 1:B) { x.b &lt;- rnorm(n, mu, sigma) mu.b &lt;- mean(x.b) sigma.b &lt;- sd(x.b) stat.b[i] &lt;- ks.test(x.b, &quot;pnorm&quot;, mu.b, sigma.b)$statistic } p.value &lt;- (sum(stat.b &gt;= stat) + 0.5) / (B + 1) list(statistics = stat, p.value = p.value, estimate = c(mean = mu, sd = sigma), stat.sim = stat.b) } pvals &lt;- replicate(1000, my.ks.normal(rnorm(100, 2, 2), B = 200)$p.value) ## check the distribution of the pvals hist(pvals) ks.test(pvals, &quot;punif&quot;) ## Warning in ks.test(pvals, &quot;punif&quot;): ties should not be present for the ## Kolmogorov-Smirnov test ## ## One-sample Kolmogorov-Smirnov test ## ## data: pvals ## D = 0.042632, p-value = 0.05277 ## alternative hypothesis: two-sided ## this is not good because pvals has only (B + 1) possible values ## while ks.test cannot handle data with ties ## check the distribution of the testing statistics stat.naive &lt;- replicate(1000, ks.test(rnorm(100, 2, 2), &quot;pnorm&quot;, 2, 2)$statistic) ## compare with the empirical distribution stat.pb &lt;- replicate(200, my.ks.normal(rnorm(100, 2, 2), B = 200)$statistic) ## plot them dens.naive &lt;- density(stat.naive) dens.pb &lt;- density(stat.pb) ## note that stat.pb tends to be smaller than stat.naiv plot(dens.pb, xlim = range(dens.naive$x)) lines(density(stat.naive), lty=2) Note that the KS statistic and the CvM statistic are functionals of the empirical distribution and the fitted parametric distribution. Faster alternatives are possible with the multiplier CLT (Kojadinovic and Yan 2012). Chi-squared test is another goodness-of-fit test. Here is an example of testing for generalized Pareto distribution. The correct degrees of freedom depends on the estimation method (Chernoff and Lehmann 1954). n &lt;- 500 theta &lt;- c(scale = 1, shape = .2) x &lt;- texmex::rgpd(n, sigma = theta[1], xi = theta[2]) fit &lt;- evir::gpd(x, threshold = 0) my_chisq_test &lt;- function(x, bins = seq(0.1, 0.9, by = 0.1), B = 1000, method = c(&quot;ml&quot;, &quot;minchisq&quot;)) { getstat &lt;- function(x, thetahat, bins) { pp &lt;- diff(c(0, bins, 1)) qx &lt;- quantile(x, bins) p &lt;- texmex::pgpd(qx, sigma = thetahat[2], xi = thetahat[1]) freq &lt;- diff(n * c(0, p, 1)) chisq.test(x = freq, p = pp)$statistic } min_chisq &lt;- function(x, init, bins) { fit &lt;- optim(init, function(th) getstat(x, th, bins)) fit } method &lt;- match.arg(method) ## observed stat n &lt;- length(x) thetahat &lt;- evir::gpd(x, threshold = 0)$par.ests if (method == &quot;minchisq&quot;) thetahat &lt;- min_chisq(x, thetahat, bins)$par stat &lt;- getstat(x, thetahat, bins) if (B &lt;= 0) return(stat) ## bootstrap stat stat.b &lt;- double(B) for (i in 1:B) { x.b &lt;- texmex::rgpd(n, sigma = thetahat[2], xi = thetahat[1]) thetahat.b &lt;- evir::gpd(x.b, threshold = 0)$par.ests if (method == &quot;minchisq&quot;) thetahat.b &lt;- min_chisq(x.b, thetahat.b, bins)$par stat.b[i] &lt;- getstat(x.b, thetahat.b, bins) } p.value &lt;- (sum(stat.b &gt;= stat) + 0.5) / (B + 1) list(statistics = stat, p.value = p.value, estimate = thetahat, stat.sim = stat.b) } my_chisq_test(x)$p.value ## [1] 0.6938062 y &lt;- rlnorm(500) my_chisq_test(y)$p.value ## [1] 0.007492507 ## replicated p-value should follow U(0, 1) under H0 ## pvals &lt;- replicate(500, my_chisq_test(texmex::rgpd(n, sigma = theta[1], xi = theta[2]))$p.value) ## compare the distribution of the testing statistic with chi-squared stat.ch &lt;- replicate(1000, my_chisq_test(texmex::rgpd(n, sigma=theta[2], xi=theta[1]), B = 0, method = &quot;minchisq&quot;)) stat.ml &lt;- replicate(1000, my_chisq_test(texmex::rgpd(n, sigma=theta[2], xi=theta[1]), B = 0, method = &quot;ml&quot;)) ## hist(stat.ml, prob=TRUE, breaks = 30) plot(density(stat.ch)) kdens &lt;- density(stat.ml) lines(kdens$x, kdens$y, col = &quot;blue&quot;) curve(dchisq(x, df = 7), add = TRUE, col = &quot;red&quot;) curve(dchisq(x, df = 9), add = TRUE, col = &quot;purple&quot;) 8.3 Block bootstrap n &lt;- 200 x &lt;- stats::arima.sim(list(ar = 0.5), n) + 2 nmblk &lt;- function(n, l) { b &lt;- n / l # assuming that is an integer idx &lt;- sample(seq(1, n - l + 1, by = l), b, replace = TRUE) c(outer(0:(l - 1), idx, &quot;+&quot;)) } mvblk &lt;- function(n, l) { b &lt;- n / l idx &lt;- sample(1:(n - l + 1), b, replace = TRUE) c(outer(0:(l - 1), idx, &quot;+&quot;)) } blkboot &lt;- function(tseries, statistic, R, l) { n &lt;- length(tseries) ## observed statistic stat &lt;- statistic(tseries) ## nonmoving block bootstrap nm.stat &lt;- replicate(R, statistic(tseries[nmblk(n, l)])) ## moving block bootstrap mv.stat &lt;- replicate(R, statistic(tseries[mvblk(n, l)])) list(stat = stat, nm.stat = nm.stat, mv.stat = mv.stat) } ## an experiment ar1 &lt;- function(x) cor(x[-1], x[-length(x)]) do1rep &lt;- function(n, theta, l) { x &lt;- arima.sim(list(ar = theta), n) bt &lt;- blkboot(x, ar1, 1000, l) c(bt$stat, sd(bt$nm.stat), sd(bt$mv.stat)) } sim &lt;- replicate(200, do1rep(100, 0.5, 10)) 8.4 Semiparametric bootstrap Heffernan and Tawn (2004) applied a semiparametric bootstrap method (Davison 1997) in multivariate extreme value modeling. The challenge here is that, although univariate margins are fitted fine with generalized extreme value (GEV) distributions, an extreme-value dependence structure may be too strong an assumption to be practical. How does one obtain bootstrap samples of a semiparametric model where the marginal models are specified but the dependence structure is not? To ensure that the bootstrap samples replicate both the marginal and the dependence features ofthe data, Heffernan and Tawn (2004) proposed a two-step bootstrap algorithm. A nonparametric bootstrap is employed first, ensuring the preservation of the dependence structure; then a parametric step is carried out to assess the uncertainty in the estimation of the parametric marginal models. The precise procedure is as follows. The original data are first transformed to have Gumbel margins using the fitted marginal models from the original data. A nonparametric bootstrap sample is then obtained by sampling with replacement from the transformed data. We then change the marginal values of this bootstrap sample, ensuring that the marginal distributions are all Gumbel and preserving the associations between the ranked points in each component. Specifically, for each \\(i\\), \\(i = 1, \\ldots, d\\), where \\(d\\) is the multivariate dimension, replace the ordered sample of component \\(Y_i\\) with an ordered sample of the same size from the standard Gumbel distribution. The resulting sample is then transformed back to the original margins by using the marginal model that was estimated from the original data. The bootstrap samples obtained this way have desired univariate marginal distributions and dependence structure entirely consistent with the data as determined by the associations between the ranks of the components of the variables. bootHT &lt;- function(rkmat) { nr &lt;- nrow(rkmat) nc &lt;- ncol(rkmat) ## resampling rows idx &lt;- sample(1:nr, nr, replace=TRUE) rkmat.bt &lt;- rkmat[idx, ] ## reordering iid uniform variables for each column vv &lt;- matrix(runif(nr * nc), nr, nc) sapply(1:nc, function(i) sort(vv[,i])[rkmat.bt[,i]]) } ns &lt;- 6 nt &lt;- 10 umat &lt;- copula::rCopula(nt, copula::normalCopula(0.6, dim = ns, dispstr = &quot;ar1&quot;)) rkmat &lt;- apply(umat, 2, rank, ties.method = &quot;random&quot;) set.seed(123) umat.bt &lt;- bootHT(rkmat) ht &lt;- replicate(1000, bootHT(rkmat)) str(ht) ## num [1:10, 1:6, 1:1000] 0.344 0.333 0.467 0.188 0.467 ... hist(ht[3, 3, ]) hist(ht[4, 5, ]) plot(ht[2, 3, ], ht[2, 4, ]) What if the data is not balanced and the blocks are of different sizes? 8.5 Multiplier bootstrap 8.5.1 Multiplier central limit theorem The theoretical background and presentation of the multiplier CLT can be found in Section~2.9 of Van Der Vaart and Wellner (1996). Let \\(X_1, \\ldots, X_n\\) be a random sample from a distribution \\(P\\). Let \\(\\delta_x(t) = I(x &lt;= t)\\). With the notation \\(Z_i(t) = \\delta_{X_i}(t) - P(t)\\), the empirical CLT can be written as \\[ \\frac{1}{\\sqrt{n}} \\sum_{i = 1}^n Z_i \\to \\mathbb{G} \\] where \\(\\mathbb{G}\\) is a Brownian bridge. Let \\(\\xi_1, \\ldots, \\xi_n\\) be a set of iid random variables with mean zero and variance 1, and independent of \\(X_1, \\ldots, X_n\\). The multiplier CLT asserts that \\[ \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n \\xi_i Z_i \\to \\mathbb{G}, \\] under some conditions about the (Donsker) class of the distribution \\(P\\). A more refined and deeper result is the conditional multiplier CLT which states that \\[ \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n \\xi_i Z_i \\to \\mathbb{G}, \\] given almost every sequence of \\(Z_i, Z_2, \\ldots\\), under only slightly stronger conditions. For illustration, consider a scalar. We first look at the unconditional version; that is, the observed data is not fixed. n &lt;- 100 nrep &lt;- 1000 ## CLT and Multiplier CLT do1rep &lt;- function(n) { x &lt;- rexp(n) z1 &lt;- sum(x - 1) / sqrt(n) z2 &lt;- sum((x - 1) * rnorm(n)) / sqrt(n) z3 &lt;- sum((x - 1) * ifelse(runif(n) &lt; 0.5, 1, -1)) / sqrt(n) c(z1, z2, z3) } clt &lt;- replicate(nrep, do1rep(n)) ## check normality of each component qqnorm(clt[1,], xlim = c(-3, 3), ylim = c(-3, 3), main = &quot;&quot;) qqline(clt[1,]) qqnorm(clt[2,], xlim = c(-3, 3), ylim = c(-3, 3), main = &quot;&quot;) qqline(clt[2,]) qqnorm(clt[3,], xlim = c(-3, 3), ylim = c(-3, 3), main = &quot;&quot;) qqline(clt[3,]) Now we look at the conditional version where the observed data are conditioned on. ## Conditional multiplier CLT x &lt;- rexp(n) ## given one sample cclt1rep &lt;- function(x) { n &lt;- length(x) z2 &lt;- sum((x - 1) * rnorm(n)) / sqrt(n) z3 &lt;- sum((x - 1) * ifelse(runif(n) &lt; 0.5, 1, -1)) / sqrt(n) c(z2, z3) } cclt &lt;- replicate(nrep, cclt1rep(x)) ## par(mfrow=c(1, 2), mar=c(2.5, 2.5, 0.1, 0.1), mgp=c(1.5, 0.5, 0)) qqnorm(cclt[1,], xlim = c(-3, 3), ylim = c(-3, 3), main = &quot;&quot;) qqline(cclt[1,]) qqnorm(cclt[2,], xlim = c(-3, 3), ylim = c(-3, 3), main = &quot;&quot;) qqline(cclt[2,]) The process version retains the dependence structure which saves much computing time in many applications such as goodness-of-fit tests. uu &lt;- (1:(2 * n) + 0.5) / (2 * n + 1) tt &lt;- qexp(uu) ## sampling from the distribution of the KS statistic ks1rep &lt;- function(n, tt) { x &lt;- rexp(n) ## rate &lt;- 1 / mean(x) ## using the true rate parameter in pexp ## if estimate is used, it will be a different distribution indXt &lt;- sapply(tt, function(t) ifelse(x &lt;= t, 1, 0)) Ft &lt;- matrix(pexp(tt), n, length(tt), byrow = TRUE) z1 &lt;- colSums(indXt - Ft) / sqrt(n) ## z1 &lt;- sqrt(n) * (ecdf(x)(tt) - pexp(tt)) ## equivalent but less visual z2 &lt;- colSums( rnorm(n) * (indXt - Ft) ) / sqrt(n) c(max(abs(z1)), max(abs(z2))) } system.time(ksSamp &lt;- replicate(nrep, ks1rep(n, tt))) ## user system elapsed ## 2.303 0.000 2.303 ks1cclt &lt;- function(x, tt) { n &lt;- length(x) indXt &lt;- sapply(tt, function(t) ifelse(x &lt;= t, 1, 0)) Ft &lt;- matrix(pexp(tt), n, length(tt), byrow = TRUE) z &lt;- colSums( rnorm(n) * (indXt - Ft) ) / sqrt(n) max(abs(z)) } system.time(ksMult &lt;- replicate(nrep, ks1cclt(x, tt))) ## user system elapsed ## 2.101 0.000 2.101 ran &lt;- range(c(ksSamp, ksMult)) qqplot(ksSamp[1,], ksSamp[2,], main = &quot;&quot;, xlim = ran, ylim = ran, xlab = &quot;parametric bootstrap&quot;, ylab = &quot;multiplier bootstrap&quot;) abline(0, 1) qqplot(ksSamp[1,], ksMult, main = &quot;&quot;, xlim = ran, ylim = ran, xlab = &quot;parametric bootstrap&quot;, ylab = &quot;conditional multipler bootstrap&quot;) abline(0, 1) Application of the multiplier CLT needs the asymptotic representation of the random quantities or process of interest. Question: for goodness-of-fit tests with unknown parameters, how would the procedure of the conditional multiplier approach change? This is the subject of Kojadinovic and Yan (2012). 8.6 Exercises Suppose that \\(X\\) and \\(Y\\) are independent \\(\\Gamma(\\alpha_1, \\beta_1)\\) and \\(\\Gamma(\\alpha_2, \\beta_2)\\) variables, where \\(\\Gamma(a, b)\\) have mean \\(a b\\). We are interested in point and interval estimation of \\(\\theta = \\mathbb{E}(X) / \\mathbb{E}(Y)\\) based on two independent samples of size \\(n_1\\) and \\(n_2\\), respectively. Consider for example \\(\\alpha_1 = \\beta_1 = 2\\), \\(\\alpha_2 = 4\\), \\(\\beta = 2\\), \\(n_1 = 10\\) and \\(n_2 = 15\\). Set the random seed to be 123 for reproducibility. Let \\(\\bar X\\) and \\(\\bar Y\\) be the sample means. Consider statistic \\(T = \\bar X / \\bar Y\\). Given the sample, draw bootstrap samples of \\(T\\) using the nonparametric method and the parametric method with sample size \\(B = 1000\\). Correct the bias of \\(T\\) in estimating \\(\\theta\\). Construct a 95% bootstrap percentile confidence interval for \\(\\theta\\). Repeat the experiments 1000 times. Compare the average bias with the exact bias; compare the empirical coverage of the 95% bootstrap confidence interval with the nominal level. One goodness-of-fit diagnosis is the QQ plot. Consider a random sample of size \\(n\\) from \\(N(\\mu, \\sigma^2)\\). A QQ plot displays the empirical quantiles against the theoretical quannntiles. For uncertainty assessment, a pointwise confidence interval constructed from simulation is often overlaid . In practice, the parameters of the distribution to be checked are unknown and the estimation uncertainty needs to be take into account. Let \\(n = 10\\), \\(\\mu = 0\\), and \\(\\sigma^2 = 1\\). Construct a QQ plot with pointwise confidence intervals with known \\(\\mu\\) and \\(\\sigma^2\\). Construct a QQ plot with pointwise confidence intervals with estimated \\(\\mu\\) and \\(\\sigma^2\\). The uncertainty in estimated parameters can be realized by bootstrapping. Repeat with sample size \\(n \\in \\{20, 30\\}\\). References "],["git-setup.html", "A Git Setup A.1 Git for Windows installer", " A Git Setup To participate in the git lesson, you need to: Download and install R RStudio Desktop git: Windows - to install see section A.1 below. OS X ≥ 10.9 OS X ≤ 10.8 snow-leopard The location of the Git executable in RStudio is set in Tools &gt; Global Options… &gt; Git/SVN as shown in the screenshot below. The default location of /usr/bin/git won’t work for most people, so set the location of Git executable as follows: Windows = C:/Program Files/Git/bin/git.exe OS X = /usr/local/bin/git If you need to change this location setting, you will need to restart RStudio for the new Git location to apply. Setup your SSH RSA key if necessary in RStudio - if your SSH RSA key is (none) instead of ~/.ssh/id_rsa or similar, then click on the button to Create RSA key… Have a github.com account, and Copy your SSH RSA key to github.com - in the RStudio window below click on View public key and copy the public key to your account as explained in step 2 onwards: https://help.github.com/en/articles/adding-a-new-ssh-key-to-your-github-account Make sure to test your GitHub connection by opening a shell in RStudio using Tools &gt; Terminal &gt; New Terminal and run the command to test your account as described in https://help.github.com/en/articles/testing-your-ssh-connection otherwise you may run into trouble with RStudio prompt window overflowing with the authenticity prompt. Install the tidyverse and modelr packages in RStudio. A.1 Git for Windows installer These instructions1 are for Windows only: Click on Next four times (two times if you’ve previously installed Git). You don’t need to change anything in the Information, location, components, and start menu screens. Select Use the nano editor by default and click on Next. Keep Git from the command line and also from 3rd-party software selected and click on Next. Click on Next. Select Use the native Windows Secure Channel library, and click Next. Keep Checkout Windows-style, commit Unix-style line endings selected and click on Next. Select Use Windows’ default console window and click on Next. Leave all three items selected, and click on Next. Do not select the experimental option. Click Install. Click on Finish. These Git Windows installer steps are from the Software Carpentry setup page.↩ "],["git-lesson.html", "B Git Lesson B.1 Automated Version Control B.2 Setup B.3 Creating a Repository B.4 Setting up Git Authorship B.5 Tracking Changes B.6 Undo Changes B.7 Explore History B.8 Next Steps", " B Git Lesson Adapted from Software Carpentry’s Git lesson, sections 1 through 7. The primary difference is we’re learning RStudio’s git interface instead of using direct git commands. Teaching 25 min Exercises 5 min Learning Goals What is version control and why should I use it? Where does Git store information? How do I record changes in Git? How do I check the status of my version control repository? How do I record notes about what changes I made and why? How can I identify old versions of files? How do I review my changes? How can I recover old versions of files? How can I tell Git to ignore files I don’t want to track? How do I share my changes with others on the web? Learning Objectives Understand the benefits of an automated version control system. Understand the basics of how Git works. Create a local Git repository. Go through the modify-add-commit cycle for one or more files. Explain where information is stored at each stage of that cycle. Distinguish between descriptive and non-descriptive commit messages. Identify and use Git commit numbers. Compare various versions of tracked files. Restore old versions of files. Configure Git to ignore specific files. Explain why ignoring files can be useful. Explain what remote repositories are and why they are useful. Push to or pull from a remote repository. Key Points Version control is like an unlimited ‘undo’. Version control also allows many people to work in parallel. Initialize a Git repository. Git stores all of its repository data in the .git/ directory. See the status of a repository. Files can be stored in a project’s working directory (which users see), the staging area (where the next commit is being built up) and the local repository (where commits are permanently recorded). Checking the box puts files in the staging area. Commit saves the staged content as a new commit in the local repository. Write a commit message that accurately describes your changes. Diff displays differences between commits. Checkout recovers old versions of files. The .gitignore file tells Git what files to ignore. A local Git repository can be connected to one or more remote repositories. Use the HTTPS protocol to connect to remote repositories only if you do not have commit access, otherwise set up SSH with RSA keys. Push copies changes from a local repository to a remote repository. Pull copies changes from a remote repository to a local repository. B.1 Automated Version Control Even if you aren’t collaborating with other people, automated version control is much better than this situation: A key difference of the Git version control system from the “Track Changes” in Microsoft Word is the database of changes is stored separately from the document. We will see where these changes are stored at the end of our next section. Several incentives for using version control according to a commenter on StackOverflow2 are: Have you ever: Made a change to code, realised it was a mistake and wanted to revert back? Lost code or had a backup that was too old? … Wanted to see the difference between two (or more) versions of your code? Wanted to prove that a particular change broke or fixed a piece of code? Wanted to review the history of some code? Wanted to submit a change to someone else’s code? Wanted to share your code, or let other people work on your code? Wanted to see how much work is being done, and where, when and by whom? Wanted to experiment with a new feature without interfering with working code? In these cases, and no doubt others, a version control system should make your life easier. Most often though, we use version control as our magic undo button for restoring plain text files like R source code: B.2 Setup Please setup R, RStudio, git, your SSH keys, create your GitHub account, and install the R packages as explained in appendix A. B.3 Creating a Repository RStudio automates repository creation for us, by tying it into the RStudio project. To create a local Git repository, make sure you check the box Create a git repository when you run File &gt; New Project… &gt; New Directory &gt; New Project That check box enables an additional Git tab in RStudio: The reason we see the Git tab is because the git program creates a directory .git/ inside our project directory. Never delete this directory, because this is your Git database that stores all of your changes and history. You cannot see this special .git/ directory unless you Show hidden files in RStudio. But let’s disable the Show hidden files now that we know where our .git/ directory lives. B.4 Setting up Git Authorship Tell Git who you are by clicking on the Git tab in RStudio and opening More &gt; Shell… Check what your git configuration looks like by running the command: git config --global --list #&gt; Output of the above command might look similar to: #&gt; #&gt; user.email=firstname.lastname@uconn.edu #&gt; user.name=Firstname Lastname #&gt; core.autocrlf=input If you have never used git on your particular computer before, you will have to set your global user.name and user.email. The commands to do that are: git config --global user.name &quot;Firstname Lastname&quot; git config --global user.email firstname.lastname@uconn.edu Of course, replace &quot;Firstname Lastname&quot; and firstname.lastname@uconn.edu with your actual name and e-mail. You can re-run the --list command above to check your new settings. B.5 Tracking Changes We see some yellow question marks in our Git tab: The yellow question marks tell us that git is not tracking those files; if the files were to change, git would not be able to help us undo the change. To start tracking the files, click on the Staged checkboxes next to the files: Click on the Commit button and enter a Commit message such as “Create RStudio project”: Then click the Commit button to save the files with the message to the git database: You created your first git commit! Each commit has a unique version hash associated with it. Older version control systems used to use versions like 1, 2, 3… however newer systems like Git no longer uses sequential numbers because that causes problems with collaboration. Instead Git creates a hash; in the screenshot above, we can see the hash version identifier is 974b832. Git creates the creates the unique by using information about the files, your author name and e-mail, the time at which the commit happened, etc. Why did we need to check the boxes next to the files in the Staged column? The Git stage is a place to include multiple files with a related change. You can think of the Git stage like the small “staging” area under your feet where people gather to take a photograph. Most often though, only one file is changed at a time, which would make our “photograph” of a single file more like selfie. If we close those pop up windows, we now see that our stage is empty: After taking the photo, our friends have moved off the stage to free the area for taking future photos. Our goal when using Git is always to have a “clean” stage, because that means all of our work is saved. Now create another commit with our first file model.R. Click on File &gt; New File &gt; R Script and run the script: library(tidyverse) library(modelr) sim1 ggplot(sim1, aes(x, y)) + geom_point() Commit these changes with the message “Inspect raw data”. Let’s add more lines to our script to fit a linear model: library(tidyverse) library(modelr) sim1 model_lm &lt;- lm(y ~ x, data = sim1) coef &lt;- coef(model_lm) coef ggplot(sim1, aes(x, y)) + geom_point() + geom_abline(intercept = coef[1], slope = coef[2]) Note how now we see a blue “M” icon in the Status column indicating that our tracked file has been “Modified”: Don’t commit our new changes just yet. Instead click on the Diff button: Click on the Commit button as usual. This creates an error: Fix this by clicking on the Staged checkbox and then click Commit. B.6 Undo Changes Sometimes a script stops working because of accidental changes. Perhaps a chunk of code was accidentally deleted and replaced with some junk text. How would we repair this with our Git history? library(tidyverse) library(modelr) fja3q2rl;js We have saved the problematic file and Git sees it as modified: One possible solution is to look back at the previous history and copy the code, but the really quick and simple fix is using Git’s Revert button instead. Clicking on Diff and then Revert restores the tracked file to the last commit version. Now our model.R file is back to the last commit version and our stage is clean because all files are the same as the last commit version: library(tidyverse) library(modelr) sim1 model_lm &lt;- lm(y ~ x, data = sim1) coef &lt;- coef(model_lm) coef ggplot(sim1, aes(x, y)) + geom_point() + geom_abline(intercept = coef[1], slope = coef[2]) Instead of going back to the last commit version we may want to go back to a much older version, say from several months ago. RStudio does not have a quick way of going back further than the last version, so we have to access the full power of the Git from the command line. In RStudio, click on Tools &gt; Shell… to open a shell at your Git directory. Then to list all your recent commits, in the shell type git log and hit enter: git log #&gt; commit 17a6f9a4fbcfdbb8091965ef75742ec3fc1f67cb (HEAD -&gt; master) #&gt; Author: Pariksheet Nanda &lt;pariksheet.nanda@uconn.edu&gt; #&gt; Date: Thu Aug 29 10:25:20 2019 -0400 #&gt; #&gt; Run linear model and add to plot #&gt; #&gt; commit c9da9361868d5f568471c14dd8b8b29e72ea5236 #&gt; Author: Pariksheet Nanda &lt;pariksheet.nanda@uconn.edu&gt; #&gt; Date: Thu Aug 29 10:17:26 2019 -0400 #&gt; #&gt; Inspect raw data #&gt; #&gt; commit 974b8325da19cf35bb5e73639943b9bfee5c4091 #&gt; Author: Pariksheet Nanda &lt;pariksheet.nanda@uconn.edu&gt; #&gt; Date: Thu Aug 29 09:45:36 2019 -0400 #&gt; #&gt; Create RStudio project Note how instead of the abbreviated 7 letter hash we now see the full 40 letter hash; for example instead of 974b832 we see our first commit version hash is actually 974b8325da19cf35bb5e73639943b9bfee5c4091. To use one of these old commits, we can use the full hash. Let’s say we want our code at the “Inspect raw data” state before we added the linear model. In the shell we would run the Git command: git checkout c9da9361868d5f568471c14dd8b8b29e72ea5236 model.R Note that we must specify the model.R file at the end we want to restore. Going from the shell back to RStudio, we can save the older version of the file as a new commit with a message like “Remove linear model fit”: In the shell, if we accidentally neglected to specify the file to restore, we will run into a detached HEAD state where none of our new history will be saved: git checkout c9da9361868d5f568471c14dd8b8b29e72ea5236 #&gt; Note: checking out &#39;c9da9361868d5f568471c14dd8b8b29e72ea5236&#39;. #&gt; #&gt; You are in &#39;detached HEAD&#39; state. You can look around, make experimental #&gt; changes and commit them, and you can discard any commits you make in this #&gt; state without impacting any branches by performing another checkout. #&gt; #&gt; If you want to create a new branch to retain commits you create, you may #&gt; do so (now or later) by using -b with the checkout command again. Example: #&gt; #&gt; git checkout -b &lt;new-branch-name&gt; #&gt; #&gt; HEAD is now at c9da936 Inspect raw data Running into this detached HEAD state from forgetting to write the file name is common typo, and to fix the detached HEAD state we need to tell Git to get back to our default master branch: git checkout master #&gt; Previous HEAD position was c9da936 Inspect raw data #&gt; Switched to branch &#39;master&#39; Phew! Now Git behavior is back to normal. B.7 Explore History Now that we have a few commits in our history, click on the History button with a clock icon: This opens up a window with our 4 commits. You can click on the commit and the modified file to see which lines were added and removed: B.8 Next Steps Read sections 8 onwards of the Software Carpentry Git lesson. If you enjoy using Git or R and want to teach others to use these tools alongside experienced volunteer instructors, consider getting your free Carpentries instructor certification. There are several certified Carpentries instructors at UConn and we would be happy to talk to you about our workshops. https://stackoverflow.com/a/1408464↩ "],["references.html", "References", " References "]]
